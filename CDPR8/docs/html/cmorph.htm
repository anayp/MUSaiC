<!DOCTYPE html>
<html lang="en">
<!-- cmorph.htm  - HTML5 version -->
<html>

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>CDP MORPH Functions</title>
<meta charset="UTF-8" />
	<link rel = "stylesheet"
	 type = "text/css"
	 href = "cdpmanshtml5.css" />
<link rel="icon"  href="images/cdp_favicon.ico">
    <style>
	a { text-decoration: none }
	a:hover { color:#FF3333;
          text-decoration: underline }          	
    </style>
</head>

<body>

<div id = "left"> <!-- Keep indexing on left ABOVE headlines so index goes to top of page -->

  <p>
  <div align = "center">
  <IMG SRC = "images/cdpcircs90.jpg"></a>
  </div>
  </p>

  <p>
  <nav>
  <!-- list-style-type NOT removing bullets in IE9, using Definition List -->
  <dl>
  <dt><a href="ccdpndex.htm" Target="_top"><b>Main Index</b></a>
  <dt><a href="cspecndx.htm" Target="_top"><b>Spectral Index</b></a> 
  <dt><a href="filestxt.htm" Target="_blank"><b>File Formats</b></a>
  <hr>
  <br>
  <dt><a href="#MORPHLIST"><b>MORPH:</b></a>
  <dt>&nbsp;&nbsp;<a href = "#BRIDGE"><b>BRIDGE</b></a>
  <dt>&nbsp;&nbsp;<a href = "#GLIDE"><b>GLIDE</b></a>
  <dt>&nbsp;&nbsp;<a href = "#MORPH"><b>MORPH</b></a>
  <br /><br />
  <b>OTHERS:</b><br>
  <dt><a href = "#NEWMORPH"><b>NEWMORPH</b></a>
  <dt><a href = "#NEWMORPH2"><b>NEWMORPH2</b></a>
  <!-- 
  <br /><br /> 
  <dt><a href="#MORPHTECHNICAL">Technical Discussion</a> <dd> Audio Morphing
  <br /><br />
   -->
  </dl>
  </p>

</div>  <!-- End of left index panel -->

<!-- ********************************************************** -->
<div id = "right"> <!-- Keep headlines here so index goes to top of page -->

   <div id = "head">

   <!-- 
   <p><IMG SRC="images/cdpcircs.jpg" align=left ALT="CDP circles logo"></a></p>
   -->
   <div align=center>
   <br>
   <img src="images/cdplogo2.jpg" ALT="CDP Logo">
   </div>

   <h1 align=center>CDP Spectral MORPHING</h1>
   <h2 align=center><font color="#3366ff"> (with Command Line Usage)</font></h2>
   </div>  <!-- End of 'head' -->


<!-- ========================================================================= -->
<h2 align = "center" id="MORPHLIST">Functions to Morph Transitions Between Sounds</h2>

<dl>
<dt><a href="#BRIDGE">MORPH <b>BRIDGE</b></a> <dd>Interpolate between a specified window 
in one file, and another window specified in another file
<dt><a href="#GLIDE">MORPH <b>GLIDE</b></a> <dd>Interpolate between two single window spectra
<dt><a href="#MORPH">MORPH <b>MORPH</b></a> <dd>Morph between one spectrum and another, 
where spectra may be time-varying
<dt><a href="#NEWMORPH"><b>NEWMORPH</b></a> <dd>Morph between dissimilar spectra
<dt><a href = "#NEWMORPH2"><b>NEWMORPH2</b></a><dd>Morph frequencies of spectral peaks</dd>

<br />
<!-- 
<dt><a href="#MORPHTECHNICAL">Technical Discussion</a> <dd> Audio Morphing</dd>
 -->
</dl>

<hr><!-- ********************************************************** -->

<h2 id="BRIDGE">MORPH BRIDGE &#150; make a bridging-interpolation between 
two sound spectra by interpolating between 2 time-specified windows in 
the 2 infiles</h2>

<h3>
Usage
</h3>
<b>morph bridge mode</b>  <i>infile1 infile2 outfile</i> 
[<b>-a</b><i>start</i>] [<b>-b</b><i>end</i>] [<b>-c</b><i>sf2</i>] 
[<b>-d</b><i>ef2</i>] [<b>-e</b><i>sa2</i>] [<b>-f</b><i>ea2</i>]<br>

<h3>
Modes
</h3> 

<blockquote>
<b>1</b> &nbsp; Output level is the direct result of interpolation<br>
<b>2</b> &nbsp; Output level follows moment to moment minimum of the 2 <i>infile</i> 
amplitudes<br>
<b>3</b> &nbsp; Output level follows moment to moment amplitude of <i>infile1</i><br>
<b>4</b> &nbsp; Output level follows moment to moment amplitude of <i>infile2</i><br>
<b>5</b> &nbsp; Output level moves, through interpolation, from that of 
<i>infile1</i> to that of <i>infile2</i><br>
<b>6</b> &nbsp; Output level moves, through interpolation, from that of 
<i>infile2</i> to that of <i>infile1</i><br>
</blockquote>

<h3>
Parameters
</h3> 

<blockquote>
<i>infile, infile2</i> &#150; input analysis files made with PVOC<br>
<i>outfile</i> &#150; output analysis file<br>
<b>-a</b><i>start</i>  time of startwindow for interpolation, in secs:  
Default: 0.0<br>
<b>-b</b><i>end</i>  time of endwindow for interpolation, in secs:  Default: 
end_of_file<br>
<b>-c</b><i>sf2</i>  fraction of 2nd sound's frq interpolated at <i>start</i>;  
(Range: 0 to 1, Default 0)<br>
<b>-d</b><i>ef2</i>  fraction of 2nd sound's frq interpolated at <i>end</i>  
(Default 1)<br>
<b>-e</b><i>sa2</i>  fraction of 2nd sound's amp interpolated at <i>start</i>  
(Default 0)<br>
<b>-f</b><i>ea2</i>  fraction of 2nd sound's amp interpolated at <i>end</i>  
(Default 1)<br>
</blockquote>

<h3>
Understanding the MORPH BRIDGE Process
</h3>

<blockquote>
<p>
Formerly SPECINTE, this process interpolates between two existing soundfiles.  
Unlike MORPH MORPH (formerly VOCINTE), this process interpolates between the 
fixed state of one sound at a specific time in that soundfile, and the 
fixed state of the 2nd sound at a specific time in that 2nd soundfile.  
The interpolation only works smoothly with sounds of quite stable spectrum.  
</p>

<p>
You can get an idea of what this means by understanding how the vibrato 
on a sound can be lost during a BRIDGE process.  When a window (fixed 
state) is taken from the first soundfile, the data is as it were frozen 
at that point.  Then an interpolation takes place simply between the 
data in the two windows, the two 'frozen' states in each file, not on 
the data in the first file after the window taken, or on the data in 
the second file before the window taken.  Thus, if there were some vibrato 
on the first sound after the point at which the window is taken, it is 
lost.
</p>

<p>
For more unstable, or noisier sounds, use MORPH MORPH, because this actually 
works on the data <i>within</i> the time period selected.
</p>

<p>
Note that there is one time period which applies to both files.  During 
this time period, a transition is made from the 1st to the 2nd sound.
</p>

<p>
The 6 Modes provide a way to weight the process in favour of the salient 
features of the soundfiles, and which one you choose to predominate.  The 
process also allows a further degree of weighting of the amount of the 
2nd sound's frequency or amplitude interpolated at the <i>start</i> and 
<i>end</i> of the specified time.
</p>
</blockquote>

<h3>
Musical Applications
</h3>

<blockquote>
<p>
The application here is to move easily between two different sounds, each of 
which has a steady spectrum.  The stability within each sound supports this 
kind of movement from one sound to the other.  Perhaps it can be likened to 
the kind of smooth aural displacement that takes place when the harmony moves 
between triads with two notes in common (such as between G-Major and E-minor, 
E-minor and A-minor, etc.).
</p>

<p>
The MORPH BRIDGE process is designed to handle movement between sounds which 
are more (but not too) dissimilar.  It takes a great deal of delicate 
handling to achieve these types of smooth movement between sounds:  there is 
a need to trick the ear at the point of transition &shy analagous to what 
needs to happen with any harmonic modulation.  But in this case, the 
psycho-acoustics of the process are complex and still very little understood.
</p>

<p>
The various amplitude following options, for example used with sounds 
with large variations of amplitude, can be used to combine sounds in 
remarkable ways.
</p>
</blockquote>

<p>
<b>ALSO SEE:</b> <a href="#MORPH"><b>MORPH MORPH</b></a>, where there is a somewhat more 
extended discussion of sound transitions.
</p>

<p>
End of MORPH BRIDGE<br>
<a href="#MORPHLIST">Return</a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> 
to Main Index for the CDP System.<br>
<a href="cspecndx.htm" Target="_top">Return</a> 
to Spectral Index
</p>

<hr><!-- ****************************************************** -->
 
<h2 id="GLIDE">MORPH GLIDE &#150; interpolate, linearly, between 2 single 
analysis windows</h2>

<h3>
Usage
</h3>
<b>morph glide</b> <i>infile1 infile2 outfile duration</i><br>

<h3>
Parameters
</h3>

<blockquote>
<i>infile1</i> and <i>infile2</i> &#150; single-window analysis files which have been extracted with <a href="cspecedi.htm#GRAB"><b>SPEC GRAB</b></a><br>
<i>outfile</i> &#150; output analysis file<br>
<i>duration</i> &#150; duration of output sound required (secs.)<br>
</blockquote>

<h3>
Understanding the MORPH GLIDE Process
</h3>

<blockquote>
<p>
We can think of the two grabbed windows as tables of spectral data, a little 
snapshot cropped from the main source file.  The contents will be the 
frequency and amplitude information for each of the e.g. 1024 channels 
(whichever value was entered for the number of channels).  There will be 
different spectral data in each of these window-tables.
</p>

<p>
The data in <i>infile1</i> becomes the start value, channel by channel, and 
the data in <i>infile2</i> becomes the end value, channel by channel.  GLIDE 
creates a linear interpolation between the start and end values, channel by 
channel, over the <i>duration</i> specified.
</p>

<p>
Note what a linear interpolation is.  Think of a straight line drawn between 
the start and end values.  The number of values and the difference between 
those values will depend on the <i>duration</i> specified.  So we can invoke 
our visual imagination to create a picture for these two example situations:
<blockquote>
1. Widely differing values over a short duration will result in dramatically 
rising or falling lines.<br>
2. Scarcely differing values over a long duration will result in very subtle, 
gradual changes.<br>
</blockquote>
Because the interpolation is linear &shy that is, proceding in equal steps 
&shy the resulting sound is likely to comprise more or less gradual 
transitions, which is why GLIDE has been placed in the MORPH category.
</p>
</blockquote>

<h3>
Musical Applications
</h3>

<blockquote>
<p>
Whether rapid and possibly somewhat dramatic, or slow and ever so gradual, 
MORPH GLIDE provides a way to move between two sounds in a smooth way.  But 
note that the transition is never likely to be as inaudibly smooth as a full 
spectral interpolation over time as with MORPH MORPH itself.  With MORPH 
GLIDE we should hear and feel the sound being redirected from one state to 
another.  The extremes of the effects possible can therefore be described, 
perhaps, as a forcible turning on the one hand, and a hardly noticeable 
translation on the other.
</p>

<p>
When two timbrally very different windows are grabbed, GLIDE can produce 
transitions with wonderful timbral modulations.
</p>
</blockquote>

<p>
End of MORPH GLIDE<br>
<a href="#MORPHLIST">Return</a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> 
to Main Index for the CDP System.<br>
<a href="cspecndx.htm" Target="_top">Return</a> 
to Spectral Index
</p>

<hr><!-- ****************************************************** -->

<h2 id="MORPH">MORPH MORPH &#150; morph one spectrum into another</h2>

<h3>
Usage
</h3>
<b>morph morph mode</b> <i>infile infile2 outfile as ae fs fe 
expa expf</i> [<b>-s</b><i>stagger</i>]<br>

<h3>
Modes
</h3>

<blockquote>
<b>1</b> &nbsp; interpolate linearly (<i>exp</i> = 1),<br>
&nbsp;&nbsp;&nbsp;&nbsp; or over a curve of increasing slope: slow 
to faster (<i>exp</i> &gt 1)<br>
&nbsp;&nbsp;&nbsp;&nbsp; or decreasing slope: fast to slower 
(<i>exp</i> &lt 1)<br>
<b>2</b> &nbsp; interpolate over a cosinusoidal spline
</blockquote>

<h3>
Parameters
</h3>

<p>
<blockquote>
<i>infile</i> first of two analysis files to morph<br>
<i>infile2</i> second of two analysis files to morph<br>
<i>outfile</i> output analysis file, result of the morph<br>
<i>as</i>  time in seconds when the amplitude interpolation begins<br>
<i>ae</i>  time in seconds when the amplitude interpolation ends<br>
<i>fs</i>  time in seconds when the frequency interpolation begins<br>
<i>fe</i>  time in seconds when the frequency interpolation ends<br>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<b>The above times refer to time position in the <i>infile</i>, i.e., 
	the first of the two files.</b>
	</br>
<i>expa</i>  exponent of the amplitude interpolation<br>
<i>expf</i>  exponent of the frequency interpolation<br>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<b>The <i>exponent</i> controls the speed at which the amplitude
	&#47;frequency interpolation affects the <i>second</i> file, 
	i.e., the rate at which the morph is transfering to the 2<sup>nd</sup> 
	file<br>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 1 = it comes in 
	quickly and then the rate of change slows down<br>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 = it 
	comes in with a linear, steady movement<br>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&gt; 1 = it comes in 
	slowly and then the rate of change speeds up</b></br>
<b>-s</b><i>stagger</i>  time-delay of entry of 2<sup>nd</sup> file (default 
is 0.0)<br>
	<blockquote>
	<ul>
        <li> 
	MORPH MORPH works only with Mono files. (For stereo/multi-channel operation, 
	channelise the sound into mono files and process these separately.)</li>
	<li>
	If <i>infile</i> is <b>longer</b> than <i>infile2</i>, the 
	    <i>outfile</i> will terminate when <i>infile2</i> does 
	    (<i>infile</i> will be truncated).</li>
	<li>
	If <i>infile</i> is <b>shorter</b> than <i>infile2</i>, the 
	    <i>outfile</i> will continue until the end of <i>infile2</i>.</li>
	<li>
	If <i>stagger</i> is employed and <i>infile</i> is <b>longer</b> 
	    than <i>infile2</i>, the <i>end</i> time of the morph can be 
	    <i>stagger</i> plus <i>infile2</i>'s duration, but no more.</li>
	<li>	
	If <i>stagger</i> is employed, the <i>start</i> time of the 
	    morph interpolation cannot be placed before the entry of 
	    <i>infile2</i>: i.e., the <i>start</i> time value cannot be 
	    less than the <i>stagger</i> value.</li>
	</ul>
	</blockquote>
</blockquote>

<h3>
Understanding the MORPH MORPH Process
</h3>

<blockquote>
<p>
MORPH MORPH is a program which can be used to create smooth aural transitions 
between different (but fairly similar) sounds.  It does this by interpolating 
between the values in two analysis files generated by PV to analyze the 
source soundfiles and re-synthesize the <i>outfile</i> of MORPH MORPH.  The 
resulting sound will be a more or less successful interpolation between the 
two original source sounds.
</p>

<p>
It is important to understand that the interpolation takes place between the 
values in the two files <i>while they continue to evolve in time</i>.  MORPH 
interpolates each successive window in the first file with its corresponding 
(simultaneous) window in the second file, so that the two sounds are 
continuing to unfold their original morphology during the process of 
interpolation.
</p>

<p>
The start and end times for the amplitude and the frequency interpolation can 
be set separately, and this often needs to be the case to achieve a good 
morph.  Thinking through a morph might involve the following steps:
</p>


<p>
1. The morph could start at the beginning of each file, or one could listen 
for a section somewhere in the middle of the files where the spectra are 
fairly stable.  This might be a good place to locate the morph, but 
ultimately one must try something and listen to the results.
<blockquote>
<p>
It is possible that these sections do not occur at the same point in each 
file.  Suppose you would like to place the morph between times 2 and 5 
in <i>infile</i> (i.e., somewhere in the middle), and between 0 and 3 in 
<i>infile2</i> (i.e., at the beginning).  To achieve this,
	<ul>
	<li>Set the interpolation <i>start</i> and <i>end</i> times to 
	    2 sec. and 5 sec. respectively &#150; <b>NB: these times 
	    relate to the 1<sup>st</sup> input file</b>.</li>
	<li>Offset the 2<sup>nd</sup> input file by setting <i>stagger</i> 
	    to 2 sec.</li>
	<li>Thus the morph starts at time 2 sec. and ends at time 5 sec. 
	    in <i>infile</i> and starts at time 0 sec. and ends at time 3 sec. 
	    in <i>infile2</i>.</li>
	<li>You can only offset <i>infile2</i> and it can start any time 
	    before and up to (but not after) the <i>start</i> time of the 
	    morph interpolation.</li>
	<li>If <i>stagger</i> sets <i>infile2</i> to begin before 
	    the morph interpolation <i>start</i> time, the morph in 
	    <i>infile2</i> will begin at <i>start</i> - <i>stagger</i> sec.  
	    For example, when <i>start</i> = 1.0 and <i>stagger</i> = 0.5, 
	    the morphing of <i>infile2</i> will begin at 1.0 - 0.5 = 0.5 sec. 
	    into <i>infile2</i>, and the first 0.5 seconds of <i>infile2</i> 
	    disappears. [I could be wrong about this - AE.]</li>
	<li>If you set <i>stagger</i> to 2 sec. and enter an interpolation 
	    <i>start</i> time of 1 sec., it will be rejected, because 
	    it comes before the start of the 2<sup>nd</sup> file.</li>
	</ul>
It is therefore possible to lay the two files against each other with 
considerable variety and precision:
	<ul>
	<li><b>no <i>stagger</i></b> &#150; the beginning of <i>infile</i> 
	    lines up with with the beginning of <i>infile2</i>
	    <b>the morphing begins at the same time point in both 
	    files</b><br>
	    <br></li>
	<li><b><i>stagger</i> = <i>start</i></b> &#150; the beginning of 
	    <i>infile2</i> lines up with the <i>start</i> of the morph 
	    interpolation in <i>infile</i><br>
	    <b>the morphing begins at time <i>start</i> in <i>infile</i> 
	    and at the beginning of <i>infile2</i></b><br>
	    <br></li>
	<li><b><i>infile2</i> is positioned before <i>start</i></b> &#150; the 
	    beginning of <i>infile2</i> comes before the <i>start</i> 
	    of the morph interpolation in <i>infile</i><br>
	    <b>the morphing begins at time <i>start</i> in <i>infile</i> 
	    and at time <i>start</i> - <i>stagger</i> in <i>infile2</i></b></li>
	</ul>
</p>

<p>
Summary:  Thus the <i>stagger</i> parameter can be used to offset the file 
in which the section to morph comes <b>earlier</b> than the section to 
morph in the other file &#150; the value of <i>stagger</i> is the amount 
of time in seconds that it is earlier.  Make this file the second input file.  
</p>

<p>
In this way the <i>stagger</i> amount is added at the beginning of the 
second file (before it starts), such that this file comes into play that 
much later.
</p>

<p>


</blockquote>
</p>

<p>
2. Then one considers the amplitude profile of the morph sections.  It 
might be best to match this in time with the frequency components, or 
start the amplitude change a little before or a little later than the 
change which occurs in the frequency components.
</p>

<p>
3. <i>expa</i> and <i>expf</i> can then be used to adjust the changeover 
between the frequency and amplitude components of the two files.  
Sometimes both should move in the same way, and sometimes one wants the 
amplitude change to occur quicker than the frequency change, and <i>v.vs.</i> 
or in the reverse direction:  frequency components might move slowly from 
the first file to the second, while the amplitude components could move more 
quickly.  This is harder to think through than it seems, because there are in 
fact 9 different combinations, and of course the range of values &gt 1 and 
&lt 1.  The following chart might provide a point of reference:
</p>

<p>
<table border="1" cellspacing="4" bgcolor="#B0E0E6">
<caption><b>Shaping Morph Transition Characteristics with the 
<i>exponent</i> Parameter</b></caption>
<tr align=center> <!-- row count: 1 -->
  <th>Example</th>
  <th>Param</th>
  <th><i>exponent</i></th>
  <th>Change into 2<sup>nd</sup> sound</th>
</tr>
<tr align=center> <!-- row count: 2 -->
  <td ROWSPAN=2>1</td>
  <td>amp</td>
  <td><i>expa</i> = 1</td>
  <td>evenly</td>
</tr>
<tr align=center> <!-- row count: 3 -->
  <td>frq</td>
  <td><i>expf</i> = 1</td>
  <td>evenly</td>
</tr>
<tr align=center> <!-- row count: 4 -->
  <td ROWSPAN=2>2</td>
  <td>amp</td>
  <td><i>expa</i> &gt 1</td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 5 -->
  <td>frq</td>
  <td><i>expf</i> &gt 1</td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 6 -->
  <td ROWSPAN=2>3</td>
  <td>amp</td>
  <td><i>expa</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 7 -->
  <td>frq</td>
  <td><i>expf</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 8 -->
  <td ROWSPAN=2>4</td>
  <td>amp</td>
  <td><i>expa</i> &gt 1 </td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 9 -->
  <td>frq</td>
  <td><i>expf</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 10 -->
  <td ROWSPAN=2>5</td>
  <td>amp</td>
  <td><i>expa</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 11 -->
  <td>frq</td>
  <td><i>expf</i> &gt 1</td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 12 -->
  <td ROWSPAN=2>6</td>
  <td>amp</td>
  <td><i>expa</i> = 1</td>
  <td>evenly</td>
</tr>
<tr align=center> <!-- row count: 13 -->
  <td>frq</td>
  <td><i>expf</i> &gt 1</td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 14 -->
  <td ROWSPAN=2>7</td>
  <td>amp</td>
  <td><i>expa</i> = 1</td>
  <td>evenly</td>
</tr>
<tr align=center> <!-- row count: 15 -->
  <td>frq</td>
  <td><i>expf</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 16 -->
  <td ROWSPAN=2>8</td>
  <td>amp</td>
  <td><i>expa</i> &gt 1</td>
  <td>slow to faster</td>
</tr>
<tr align=center> <!-- row count: 17 -->
  <td>frq</td>
  <td><i>expf</i> = 1</td>
  <td>evenly</td>
</tr>
<tr align=center> <!-- row count: 18 -->
  <td ROWSPAN=2>9</td>
  <td>amp</td>
  <td><i>expa</i> &lt 1</td>
  <td>fast to slower</td>
</tr>
<tr align=center> <!-- row count: 19 -->
  <td>frq</td>
  <td><i>expf</i> = 1</td>
  <td>evenly</td>
</tr>
</table>
</p>

4. Other considerations:
<ul>
<li>What if the two files are at different pitch levels?  Try cutting out the 
morphing section of one of the files, creating a time-varying transposition 
(probably in the spectral domain) to the level of the other file and 
replacing it before doing the morph.<br><br></li>

<li>What if one file is pulsed and the other isn't?  Try extracting the 
amplitude envelope of the pulsed one and imposing it on the other file 
before doing the morph.  (See <a href="cgroenvl.htm#EXTRACT"><b>ENVEL 
EXTRACT</b></a> and <a href="cgroenvl.htm#IMPOSE"><b>ENVEL IMPOSE</b></a>).<br><br></li>

<li>What if one of the files has such a variable spectrum that it interferes 
with the smoothness of the morph?  Try a time varying spectral BLUR starting 
at the point where the morph is to begin.<br><br></li>

<li>What if the two sounds have distinctly different formant components?  
Try extracting the formants from one of the sounds and imposing them on the 
other.</li>
</ul>
</blockquote>

<h3>
Musical Applications
</h3>

<blockquote>
<p>
We are now familiar with the practice of gradual shape transformations 
between visual images.  The process has a wonderful surprise value as the 
first image seems to alter before our very eyes, becoming another quite 
different image, such as a face becoming that of another person.
</p>

<p>
You may also possibly have observed that just at the moment of transition, 
the first image begins to melt or distort in some way.  I say 'possibly' 
because it tends to happen very quickly, and because our eyes/brain tend 
to construct a familiar image, it's rather difficult to notice what happens 
inbetween.  However, it is very instructive to do so.  If it didn't change 
in some way before the second image made its presence felt, there would 
in fact not be a transition, just an abrupt change.  This is the 
principle of 'modulation' in action.
</p>

<p>
&#150 which is precisely where we need to turn our attention when seeking 
to carry out an audio-morph.  Modulation in music has been used up till 
now to move from one tonal region to another, and you will recall how it 
is common practice to begin by dissolving the identity of the existing 
tonal region, such as by using tonally ambigous diminished 7th harmonies.  
</p>

<p>
The idea of creating surprise and astonishment by causing one sound to 
become another is in itself easy to grasp.  What's not so easy is making 
this smooth to the point of being almost imperceptible.  Herein lies the 
art of the morph, and once again the concept of modulation is relevant.  
('Morph', by the way, is a Greek word meaning 'form'.)  This program 
gives a taste of the morphing process.  The CDP spectral domain programs 
provide many other processes that can be used to 'pre-process' sounds 
to achieve a more psycho-acoustically effective transition.
</p>

<p>
Here, the best results will be achieved by using sounds which are already 
quite similar.
</p>
</blockquote>

<p>
<b>Historical note</b>
<blockquote>
MORPH is derived from VOCINTE, which was originally written at IRCAM 
during the composition of VOX-5.  I would like to thank the many people 
there who offered me help and advice.  I would also like to thank 
Andrew Bentley who modified the first versions of the program to work 
with the (Atari-based) CDP soundfile system and to operate more 
efficiently. (Trevor Wishart)
</blockquote>
</p>


<p>
End of MORPH MORPH<br>
<a href="#MORPHLIST">Return</a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> 
to Main Index for the CDP System.<br>
<a href="cspecndx.htm" Target="_top">Return</a> 
to Spectral Index
</p>

<hr><!-- *************************NEWMORPH (1)********************************* -->

<h2 id="NEWMORPH">NEWMORPH &#150; Morph between dissimilar spectra</h2>

<h3>
Usage
</h3>
<b>newmorph newmorph 1-6</b> <i>inanalfile1 inanalfile2 outanalfile stagger startmorph endmorph exponent peaks </i> [<b>-e</b>] [<b>-n</b>] [<b>-f</b>]
<br />
<b>newmorph newmorph 7</b> &nbsp;&nbsp;&nbsp;<i>inanalfile1 inanalfile2 outanalfile peaks outcnt</i> [<b>-e</b>] [<b>-n</b>] [<b>-f</b>]
<br /><br />

<p>
Example command line to create a timbral morph:<br />
	<blockquote>
	<b><code>newmorph newmorph 1 in1.ana in2.ana out.ana 0 0 2 5 5</code></b>
	</blockquote>
</p>

<h3>
Modes
</h3>

<blockquote>
<b>1</b> &nbsp; Interpolate linearly (<i>exponent</i> = 1) between the average peak channels or over a curve of increasing (<i>exponent</i> &gt; 1) or decreasing (exp <1) slope, simultaneously moving spectral peaks, and interpolating all remaining channels.<br />
<b>2</b> &nbsp; Interpolate cosinusoidally (<i>exponent</i> = 1) between the average peak channels or over a warped cosinusoidal spline (<i>exponent</i> not equal to 1), simultaneously moving spectral peaks, and interpolating all remaining channels.<br />
<b>3</b> &nbsp;  As mode 1, using channel-by-channel calculation of peaks.<br />
<b>4</b> &nbsp;  As mode 2, using channel-by-channel calculation of peaks.<br />
<b>6</b> &nbsp; Sound 1 is (gradually) tuned to the (averaged) harmonic field of sound 2 linearly<br />
<b>6</b> &nbsp; Sound 1 is (gradually) tuned to the (averaged) harmonic field of sound 2 cosinusoidally<br />
<b>7</b> &nbsp; Sound 1 is morphed towards sound2 in <i>outcnt</i> steps, each step a new output file.
</blockquote>

<h3>
Parameters
</h3>

<blockquote>
<i>inanalfile1, inanalfile2</i> &#150; input analysis files made with PVOC<br />
<i>outanalfile</i> &#150; output analysis file<br />
<i>stagger</i> &#150; time before the entry of analysis file2<br />
<i>startmorph</i> &#150; time in the 1<sup><small>st</small></sup> file at which the morph starts<br />
<i>endmorph</i> &#150; time in the 1<sup><small>st</small></sup> file at which the morph ends<br />
<i>exponent</i> &#150; exponent of interpolation  (Range: 0.02 to 50)<br />
<i>peaks</i> &#150; number of peaks to interpolate (Range:  1 to 16)<br />
<i>outcnt</i> &#150; <b>Mode</b> 7 makes <i>outcnt</i> distinct ouput analysis files<br />
<b>-e</b> &#150; retain the loudness envelope of the first sound.  In this case the <i>outanalfile</i> is terminated when the end of the first sound is reached.<br />
<b>-n</b> &#150; there is no interpolation of anything except the peaks<br />
<b>-f</b> &#150; only frequency is determined by the peaks in analysisfile2
	<blockquote>
	The end of the interpolation must not be beyond the end of one of the files.
	</blockquote>
</blockquote>

<h3>
Understanding the NEWMORPH Process
</h3>

<blockquote>
NEWMORPH is similar to MORPH MORPH in that there are two input analysis files and there is a gradual movement from the first to the second, with start and end times for the morph and <i>exponent</i> and <i>stagger</i> parameters.  Where it differs is that NEWMORPH's morph is focused on the peaks of the two spectra.  This helps the program to handle dissimilar spectra, whereas MORPH MORPH works best with similar sounds.  There are also a larger number of modes, adding channel-by-channel operation, tuning and  morphing in steps.
</blockquote>

<!--
<h3>
Musical Applications
</h3>

<blockquote>
...
</blockquote>
-->

<p>
End of NEWMORPH<br />
<a href="#MORPHLIST"><b>Return</b></a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> to Main Index for 
the CDP System.<br />
<a href="cspecndx.htm" Target = "_top"><b>Return</b></a> to Spectral Index
</p>

<hr> <!-- ******************** NEWMORPH 2 ********************************** -->
<h2 id="NEWMORPH2">NEWMORPH2 &#150; Morph frequencies of spectral peaks</h2>

<h3>
Usage
</h3>
<b>newmorph newmorph2 1</b> &nbsp;&nbsp; <i>inanalfileA outtextfile</i> (=<i>peaksfile</i> in Modes 2-3) <i>peakcnt</i>
<br />
<b>newmorph newmorph2 2-3</b> <i>inanalfileB peaksfile outanalfile startmorph endmorph exponent peakcnt</i> [<b>-r</b><i>rand</i>]

<p>
Example command line to create a tuned morph:<br />
	<blockquote>
	<b><code>newmorph newmorph 1 in.ana peaksfile.txt out.ana 0 2 1 5</code></b>
	</blockquote>
</p>

<h3>
Modes
</h3>

<blockquote>
<b>1</b> &nbsp; Find frequencies of the most prominent spectral peaks of inanalfileA and output these in order of prominence, as a textfile list: a <i>peaksfile</i><br>
<b>2</b> &nbsp; The sound of inanalfileB is (gradually) tuned to the harmonic field specified in the <i>peaksfile</i><b>1</b>.  The <i>peaksfile</i> lists the goal-peak frequencies, in order of prominence.  
<br />
<b>3</b> &nbsp; As Mode 2, but the interpolation is cosinusoidal over time instead of linear.
</blockquote>

<h3>
Parameters
</h3>

<blockquote>
Mode <b>1</b>:<br>
<i>inanalfileA</i> &#150; input analysis file in which to find the frequencies of spectral peaks<br />
<i>outtextfile</i> &#150; output textfile (<i>peaksfile</i>), listing the frequencies of the most prominent peaks, in order of prominence <br>
<i>peakcnt</i> &#150; number of most-prominent peaks to find (Range: 1 to 16)<br><br>

Modes <b>2</b> and <b>3</b>:<br>
<i>inanalfileB</i> &#150; input analysis file to which to apply the data in the <i>peaksfile</i><br>
<i>outanalfile</i> &#150; output analysis file <br>
<i>peaksfile</i> &#150; input textfile (from Modes <b>1</b>), listing the frequencies of the most prominent peaks in order of prominence; 
<b>OR</b> a textfile containing an arbitrary list of frequencies, not necessarily those extracted from a previous file in Mode <b>1</b><br />
<i>startmorph</i> &#150; time at which the morph starts<br />
<i>endmorph</i> &#150; time at which the morph ends<br />
<i>exponent</i> &#150; exponent of interpolation (Range: 0.02 to 50). See MORPH MORPH for a discussion of this parameter.<br />
<b>-r</b>rand &#150; randomisation of the goal peak frequency (Range: 0 to 1)<br>
<i>peakcnt</i> &#150; number of most-prominent peaks to retune (Range: 1 to 16)<br><br>
</blockquote>

<h3>
Understanding the NEWMORPH2 Process
</h3>

<blockquote>
NEWMORPH2 aims to morph the most prominent frequencies of one sound towards those of another. The first pass (Mode 1) extracts the goal frequencies as a text list which becomes the <i>peaksfile</i> for Mode 2 or 3. In practice, however, the <i>peaksfile</i> can be any list of frequencies (up to 16), listed in order of prominence. NEWMORPH2 is similar to NEWMORPH's tuned modes (6 and 7), but appears to be more focussed on the spectral peaks found in the goal sound.  
</blockquote>

<!--
<h3>
Musical Applications
</h3>

<blockquote>
...
</blockquote>
-->

<p>
End of NEWMORPH2<br />
<a href="#MORPHLIST"><b>Return</b></a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> to Main Index for 
the CDP System.<br />
<a href="cspecndx.htm" Target = "_top"><b>Return</b></a> to Spectral Index
</p>


<!-- <hr> --> <!-- ****************************************************** -->
<!-- 
<h2 id="MORPHTECHNICAL">Technical Discussion of Audio Morphing</h2>

<p>
Apologies - This section is not yet completed.
</p>

<p>
1. Encapsulating these three morphing methods.
</p>

<p>
2. Some of the other functions which might be called upon to assist with the 
audio-deception of the morph.  (stretching, time-varying transposition, 
imposing formants/spectral envelopes or time-domain envelopes from one of 
the sounds to the other (before the morph), time-varying blurring ... 
</p>

<p>
3. Additional comments on the glossary item:  Linear interpolation.  Two words 
to be clear about.  First of all, an <b>interpolation</b> can ... 
<b>linear</b> means equally spaced values.  The steps between each value 
become smaller when there are more and more divisions to be made between 
the start and end values. ...
</p>

<p>
End of Technical Discussion<br>
<a href="#MORPHLIST">Return</a> to List of functions to morph between 
sounds at top of this file<br>
<a href="ccdpndex.htm" Target="_top"><b>Return</b></a> 
to Main Index for the CDP System.<br>
<a href="cspecndx.htm" Target="_top">Return</a> 
to Spectral Index
</p>
 -->




<!-- ********************************************************** -->
  <div id = "footer">
   <p>
    <address>
    Last Updated 4 Apr 2023 for CDP8<br />
    Documentation: Archer Endrich<br />
    Revisions: Robert Fraser<br>
    All observations &amp; ideas for improvement appreciated<br />
    Composers Desktop Project Ltd<br />
    Email: cdpse9@gmail.com<br />
    &#169; Copyright 1998-2023 Archer Endrich &amp; CDP<br>
    </address>
   </p>
  </div>

</div> <!-- End of 'right' (contents) indentation -->

</body>

</html>
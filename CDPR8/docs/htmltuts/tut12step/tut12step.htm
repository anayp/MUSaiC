<!DOCTYPE html>
<html lang="en">
<!-- tut12stp.htm - TUT12STEP  - HTML5 version -->
<html>

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>12-step Tutorial</title>
<meta charset="UTF-8" />
	<link rel = "stylesheet"
	 type = "text/css"
	 href = "cdpcssdf.css" />
<link rel="icon"  href="../images/cdp_favicon.ico">
    <!-- might revise this to match orig .css better -->
    <style>
	a { text-decoration: none }
	a:hover { color:#FF3333;
          text-decoration: underline }          	
    </style>
</head>

<body>

<div id = "left"> <!-- Keep indexing on left ABOVE headlines so index goes to top of page -->
  <br>&nbsp;&nbsp;
  <IMG SRC = "../images/cdpcircs90.jpg" align="center"></a>

  <p>
  <nav>
  <dl>
  <dt><a href="../../html/ccdpndex.htm" Target="_top"><b>Main Index</b></a>
  <dt><a href="../../html/tutorials.htm" Target="_top"><b>Tutorials Index</b></a> 
  <dt><a href="../../html/cgroundx.htm" Target="_top"><b>'Groucho' Index</b></a> 
  <dt><a href="../../html/cspecndx.htm" Target="_top"><b>Spectral Index</b></a> 
  <dt><a href="../../html/filestxt.htm" Target="_blank"><b>File Formats</b></a>

  <hr>
  <dt><a href="#ORIENTATION"><b>ORIENTATION</b></a> 
  <dt>&nbsp;&nbsp;<a href="#ENVIRONMENT"><b>Environment</b></a>
  <dt>&nbsp;&nbsp;<a href="#OVERVIEW"><b>Overview</b></a>
  <dt>&nbsp;&nbsp;<a href="#SUPPLEMENTARY"><b>Supplementary</b></a>
  <dt>&nbsp;&nbsp;<a href="#GETTINGSTARTED"><b>Getting Started</b></a>
  <dt>&nbsp;&nbsp;<a href="#TUTORIALS"><b>Tutorials</b></a>
  <br /><br />

<dt><b>1.</b> <a href="#STEP1"><b>SOUNDS</b></a>
<dt>&nbsp;&nbsp;<a href="#GETSOUNDS"><b>Get Sounds</b></a><br />
<dt>&nbsp;&nbsp;<a href="#EDITSOUNDS"><b>Edit sounds</b></a><br />

<br />
<dt><b>2.</b> <a href="#STEP2"><b>PLAYBACK</b></a>

<br /><br>
<dt><b>3.</b> <a href="#STEP3"><b>TRANSPOSITION</b></a>

<br /><br>
<dt><b>4.</b> <a href="#STEP4"><b>TIME CONTOURS</b></a>
<dt>&nbsp;&nbsp;<a href="#INTRO4"><b>Introduction</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TVTRANSPOSITION"><b>Time-varying</b></a><br />
<dt>&nbsp;&nbsp;<a href="#GRAPHICBP"><b>Graphic Editor</b></a><br />
<dt>&nbsp;&nbsp;<a href="#INSTANT"><b>Instant Changes</b></a><br />
<dt>&nbsp;&nbsp;<a href="#RANDOMISED"><b>Randomised</b></a><br />

<br />
<dt><b>5.</b> <a href="#STEP5"><b>ANALYSIS</b></a>
<dt>&nbsp;&nbsp;<a href="#ANALYSIS"><b>Analysis</b></a><br />
<dt>&nbsp;&nbsp;<a href="#PROCESSING"><b>Processing</b></a><br />
<dt>&nbsp;&nbsp;<a href="#RESYNTHESIS"><b>Resynthesis</b></a><br />

<br />
<dt><b>6.</b> <a href="#STEP6"><b>FILTER BANKS</b></a>

<br /><br>
<dt><b>7.</b> <a href="#STEP7"><b>DISTORTION</b></a>

<br /><br>
<dt><b>8.</b> <a href="#STEP8"><b>ENVELOPES</b></a>
<dt>&nbsp;&nbsp;<a href="#WHATISENV"><b>Envelopes</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TDAMP"><b>Time Domain</b></a><br />
<dt>&nbsp;&nbsp;<a href="#SDENV"><b>Spectral Domain</b></a><br />
<dt>&nbsp;&nbsp;<a href="#SDFORMANTS"><b>Formants</b></a><br />

<br />
<dt><b>9.</b> <a href="#STEP9"><b>TRANSITIONS</b></a>
<dt>&nbsp;&nbsp;<a href="#INTRO9"><b>Background</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TDCROSSF"><b>TD Crossfade</b></a><br />
<dt>&nbsp;&nbsp;<a href="#SDAMP"><b>SD Crossfade</b></a><br />
<dt>&nbsp;&nbsp;<a href="#ACHIEVING"><b>Morphs</b></a><br />
<dt>&nbsp;&nbsp;<a href="#OTHER9"><b>Other Processes</b></a><br />

<br />
<dt><b>10.</b> <a href="#STEP10"><b>MIXING</b></a>
<dt>&nbsp;&nbsp;<a href="#MIXCONCEPTS"><b>Approaches</b></a><br />
<dt>&nbsp;&nbsp;<a href="#SSMIXING"><b><i>Soundshaper</i></b></a><br />
<dt>&nbsp;&nbsp;<a href="#SLMIXING"><b><i>Sound Loom</i></b></a><br />

<br />
<dt><b>11.</b> <a href="#STEP11"><b>TEXTURES</b></a>
<dt>&nbsp;&nbsp;<a href="#TXPARAMS"><b>Parameters</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXNDF"><b>Note Data File</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXTGRID"><b>Timing Grid</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXHGRID"><b>Harmonic Grid</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXCHGRID"><b>Changing Grid</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXMOTIFS"><b>Motifs</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXNS"><b>Lines</b></a><br />
<dt>&nbsp;&nbsp;<a href="#TXPLAY"><b>Play</b></a><br />

<br />
<dt><b>12.</b> <a href="#STEP12"><b>MANAGEMENT</b></a>
<br /><br />
<dt><a href="#CONCLUSION"><b>CONCLUSION</b></a>
</dl>


</div>  <!----------------- End of left index panel ----------------------->

<div id = "right"> <!-- Keep headlines here so index goes to top of page -->

   <div id = "head">


	<p>
	<IMG SRC="../images/cdpcircs.jpg" ALT="CDP circles logo"><br clear>
	<b>Composers' Desktop Project</b></a>
	</p>


	<h1 id="INDEX">Get Started with CDP in 12 Steps</h1>
	<h2 align="center">by Archer Endrich</h2>

   </div>  <!-- End of 'head' -->


<!-- ========================================================================= -->
<p>
<div>
<table align=center border="1" cellpadding="3" bgcolor="#B0E0E6">
<tr>
<td><a href="#ORIENTATION"><b>Orientation</b></a></td>
<td><a href="#STEP1"><b>1. Acquire Sounds</b></a></td>
<td><a href="#STEP2"><b>2. Playback</b></a></td>
</tr>

<tr>
<td><a href="#STEP3"><b>3. Transposition</b></a></td>
<td><a href="#STEP4"><b>4. Time Contours</b></a></td>
<td><a href="#STEP5"><b>5. Analysis &amp; Re-synthesis</b></a></td>
</tr>

<tr>
<td><a href="#STEP6"><b>6. Filter Banks</b></a></td>
<td><a href="#STEP7"><b>7. Waveshape Distortion</b></a></td>
<td><a href="#STEP8"><b>8. Envelope Transfer</b></a></td>
</tr>

<tr>
<td><a href="#STEP9"><b>&nbsp;9. Transitions &amp; Morphing</b></a></td>
<td><a href="#STEP10"><b>10. Mixing</b></a></td>
<td><a href="#STEP11"><b>11. Multi-event Textures</b></a></td>
</tr>

<tr>
<td><a href="#STEP12"><b>12. Project Management</b></a></td>
<td><a href="#CONCLUSION"><b>Conclusion</b></a></td>
<td><a href="#"><b><br /></b></a></td>
</tr>
</table>
</div>
</p>

<p>
<br />
</p>

<h2 id="ORIENTATION">Orientation</h2>

<blockquote>
<p>
Before working through the 12-Step Tutorial for the first time, 
the following sections may be helpful regarding the overall CDP working 
environment and other sources of information.  
	<ul>
	<li><a href="#ENVIRONMENT"><b>Working Environment</b></a></li>
	<li><a href="#OVERVIEW"><b>Overview</b></a> of this 12-Step 
	Tutorial</li>
	<li><a href="#SUPPLEMENTARY"><b>Supplementary</b></a> Documents 
	and Charts</li>
	<li><a href="#GETTINGSTARTED"><b>Getting Started</b></a> with the 
	CDP System</li>
	<li><a href="#TUTORIALS"><b>Additional Specialist</b></a> 
	Tutorials and Sound Examples</li>
	</ul>
</p>

<h3 id="ENVIRONMENT">Basic Working Environment</h3>

<p>
Our recommended <b>Basic CDP Working Environment</b> entails having the 
following on-screen or to hand:
	<ul>
	<li>One of the 2 available CDP graphic user interfaces.  I 
	usually recommend <i>Soundshaper</i> as the most approachable, 
	and <i>Sound Loom</i> for users more familiar with the 
	CDP software.</li> <br />
	<br />

	<li>The main page of the CDP Reference Documentation: 
	double-click on <i>ccdpndex.htm</i>.  Select 'Work Offline' 
	if asked!  You can then Park (Minimise) this and only call 
	upon it for more detained information about the 
	software.  (You can only do this with one HTML document 
	at a time, so you can't do this while using this 
	Tutorial.)</li> <br />
	<br /> 

	<li>Alternatively, especially if you haven't printed it 
	out, you might use <i>CDP Files &amp; Codes</i> as your initial 
	reference document.  It goes through all the different types 
	of (mostly input) files used with the CDP software.  
	Double-click on <i>filesfrm.txt</i> to call up the frames 
	version with main text and index.  You won't need to do 
	this with this tutorial, because it links to it whenever 
	appropriate.</li> <br />
	<br /> 

	<li>A text editor, such as <i>Emacs</i> or <i>Notepad</i> 
	or <i>Wordpad</i> (not <i>Word for Windows</i>, which puts 
	in formatting codes).  If you find you are comfortable 
	with creating text files from within the GUI, you won't 
	need it.  I find a separate text editor useful, and often 
	use <i>Emacs</i> because of the block CUT and PASTE and 
	especially MACRO functions, which can significantly speed 
	up creating the more complex types of files, with many 
	lines.</li> <br />
	<br /> 

	<li>A (preferably hardback) notebook for sketching 
	diagrams and jotting down key information while you're 
	working, especially functions and parameters that 
	achieve good results, and the names of files you've 
	created while working with a specific function.</li> <br />
	<br /> 
	</ul>
</p>

<h3 id="OVERVIEW"> Overview of this 12-Step Tutorial
</h3>

<p>
This Tutorial is designed to help you get deep into the CDP Sound 
Transformation Software as quickly as possible.  The CDP software 
may involve a way of working that is unfamiliar because it is less 
graphic than much of the commercial software, but when understood, 
it is actually very straightforward and highly flexible with many 
ways for the user to design patterns and shapes.
	<ul>
	<li>It grows out of a U<small>NIX</small><sup><small>TM</small></sup>-
	like environment and can be accessed and used via a command line 
	interpreter.  This is mostly done to take advantage of the 
	<a href="../../html/filestxt.htm#BATCHFILES"><b>batch file</b></a> 
	mechanism.</li><br />
	<br />

	<li>The Graphic User Interfaces (<i>Sound Loom</i> and <i>Soundshaper</i> 
	GUIs) are minimal, mainly enabling parameter data entry via dialogue 
	boxes, but also with other graphic or semi-graphic features to help 
	with the creation of <a href="../../html/filestxt.htm#BREAKPOINTFILES">
	<b>breakpoint files</b></a> columns of numbers and sequences 
	of operations.</li><br />
	<br /> 

	<li>There are (at the time of writing) <a href="../../html/filestxt.htm">
	<b>50&#43; different types of file format </b></a> which you 
	can use to design and present data to the sound transformation 
	software.  This enables a tremendous degree of flexibility and 
	in-depth sound patterning.</li><br />
	<br /> 

	<li>Some data entry is in numerical format, such as MIDI Pitch 
	Values (MPVs) for pitch entry and durations in seconds (such as 
	0.25 for a semiquaver = 16<sup><small>th</small></sup> note at 
	crotchet = 60), but Reference Charts can make this much easier 
	than it seems at first.  In fact, this is often quicker and more 
	flexible than graphic systems.</li><br />
	<br /> 

	<li><b>The keys to success</b> are to 1) use your imaginating to 
	create rough drawings that chart changes over time or other 
	patterns before trying to enter the numerical data into files, 
	and 2) keep the Reference Charts handy.</li><br />
	<br />

	<li>The soundfile examples are not made for you.  The whole 
	point of the Tutorial is to empower you to use the software.  
	You are therefore recommended to make each example as you 
	go along, working through the 12 steps in order.  When everything 
	is made, access the <b>Playlist</b> to Play all the examples 
	for comparison purposes.  (Playlist document not prepared 
	yet.)</li><br />
	<br />

	<li>It turns out to be a powerful and straightforward way to 
	work, and promises results very hard to duplicate with other 
	software, though each package has its strong points, and the 
	CDP software is designed to be complementary.</li>
	</ul>
</p>

<h3 id="SUPPLEMENTARY"> Supplementary Documents and Charts
</h3>

<p>
There are a number of <b>supplementary documents and charts</b> 
for referencing different types of information.  They include:
	<ul>
	<li><i>The Spiral Bound Desk Reference</i> &#150; hard-copy</li>
	<li><a href="../../html/filesfrm.htm"><i>CDP Files &amp; Codes</i></a> 
	&#150; reference guide to all the codes, text and binary files created 
	by and&#47;or made by users as inputs to the CDP software (with 
	examples)</li>
	<li><a href="../../html/glossmus.htm"<i>Musical Glossary</i></a> &#150; 
	Musical Terms, with special relevance for working with sounds</li>
	<li><a href="../../html/glosstec.htm"<i>Technical Glossary</i></a> &#150; 
	Technical Terms, with special relevance for working with sounds</li>
	<li><a href="../../html/notechrt.htm"><i>Chart of Equivalent Pitch 
	Notations</i></a> &#150; MIDI Note Values, <i>Csound</i> pitch 
	notations, and Frequencies in Hz</li>
	<li><a href="../../html/gadbchrt.htm"><i>Chart of Loudness</i></a> &#150; 
	different scales of loudness compared</li>
	<li><a href="../../html/ndfchart.htm"<i>Note Data File Chart</i></a> for 
	the TEXTURE Set.</li>
	<li><a href="../../html/Txcharts.htm"<i>2 Charts</i></a> for 
	the TEXTURE Set, showing active fields.</li>
        <!--
	<li><a href="../../html/cdptshoot.htm"<i>Trouble-Shooting Guide</i></a> 
	(not yet available)</li>
        -->
	<li><a href="../../html/rpchchrt.htm"><i>Transposition &amp; Shifting 
	Chart</i></a> of inputs and outputs for the various REPITCH 
	functions.</li>
	</ul>
</p>

<h3 id="GETTINGSTARTED"> Getting Started with the CDP System
</h3>

<p>
There are a number of other documents prepared to provide tutorial help 
with the software.  These are:
	<ul>
	<li><b>CDP DemoDisk</b> &#150; CD-ROM with various examples of 
	sounds made with the CDP software, plus some documentation on 
	sound design in general:
		<ul>
		<li><i>CDP Website Examples</i> (specific worked examples 
		as on the CDP Website)</li>
		<li><i>DiceDemo</i> (showing the sequence of steps by 
		which several complex sounds were made)</li>
		<li><i>Sound-Builder Templates</i> (several multi-step 
		processing sequences, each with a full description of 
		each step, a generic batch file, and a Playlist)</li>
		<li>Various Documents about Sound Design (including sound 
		and image relationships, etc.)</li>
		</ul>
	</li>
	<li><a href = "../twSoundLoomGuide.pdf"><i>Sound Loom &amp; CDP</i></a> 
	&#150; A comprehensive survey of running the CDP software from the 
	<i>Sound Loom</i> GUI.</li>
	<li><a href="../CDPtour.htm">CDP Tour</a> &#150; An overview by Robert 
	Fraser of the whole CDP software package, with lots of insights 
	and tips.</li>
	<li><b><i>Get Started with CDP in 12 Steps</i> (this tutorial)</b></li>
	<li><i>CDP-LITE</i> &#150; 45 basic functions introduced on 2 levels, 
	with sound examples provided as <i>Soundshaper</i> Presets and 
	<i>Sound Loom</i> Instruments</li>
	<li><a href="../cma1fram.htm" Target="_top" ><i>Mastering CDP I</i></a> 
	(another introductory document)</li>
	<li><a href="../ckeyfram.htm" Target="_top"><i>A Keyhole View 
	of CDP</i></a> (focusing in on specific groups of programs)</li>
	<li><a href="../cmsdos.htm"<i>On Using MS-DOS</i></a> 
	(key commands of MS-DOS: the Command Line Interpreter)</li>
	<li><a href="../cusefram.htm" Target="_top"><i>On Using CDP</i></a> 
	(a now rather elderly intro to the CDP System)
	<li><a href="../useemacs.htm" Target="_top"><i>Key Functions of the Emacs Text 
	Editor</i></a></li>
	</ul>
</p>

<h3 id="TUTORIALS">Specialist Tutorials and Sound Examples
</h3>

<p>
The following provide guidance in certain key specialist areas (you can edit 
these links in a text editor if they are incorrect for your system):
	<ul>
	<li>for<i>GrainMill</i></li>
		<ul>
		<li><a href="../grntuts/philippos/grntutor.htm">Theocharidis</a></li>
		<li><a href="../grntuts/rwd/RDplayex.htm">Dobson</b></li>
		<li><a href="../grntuts/ae/aebigone.htm">Endrich</a></li>
		</ul>
	<li>for <a href="../drunk/drunktut.htm">Drunk</a></li>
	<li>for the Texture Set: &#150; <i>Texture Workshop</i>, on CD-ROM</li>
	<li>for Transposition and frequency shifts: &#150; <i>Transposition 
	and Shifting Workshop</i>, on CD-ROM</li>
	</ul>
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP1">Step 1: Acquiring Sounds and Basic Editing
</h2>

<blockquote>
<p>
<b>Step 1</b> is about:
	<ul>
	<li><a href="#GETSOUNDS"><b>Acquiring Sounds</b></a></li>
	<li><a href="#EDITSOUNDS"><b>Basic Editing</b></a></li>
	</ul>
</p>

<h3 id="GETSOUNDS">Acquiring Sounds</h3>

<p>
<b>Sounds brought directly to computer hard disk:</b>
	<ol>
	<li><b>from sample CDs</b> &#150; Copy to hard disk.
		<ul>
		<li><b>Remember to avoid any folder or soundfile 
		names with spaces in them when working with 
		CDP.</b></li><br />
		<br />

		<li>If the soundfiles are in <b>.wav</b> format and you 
		are working in a <b>.wav</b> context, there is nothing 
		more that needs to be done, unless you find that the 
		file isn't recognised by the CDP software.  In this 
		case, the problem probably lies in a non-standard header.  
		If you make a copy of it using CDP's COPYSFX, a 
		new header is created, compliant with the full 
		<b>.wav</b> standard, which is what CDP uses.</li><br />
		<br />

		<li>If these are <b>.wav</b> and you are working in an 
		<b>.aif</b> context, you will need to convert to 
		<b>.aif</b> (or <b>.afc</b> or <b>.aifc</b>) by making 
		a copy using CDP's COPYSFX.</li> <br />
		<br />

		<li>Similarly, if these are <b>.aif</b> and you are 
		working in a <b>.wav</b> context, you will need to 
		convert them to <b>.wav</b> using CDP's COPYSFX 
		program.</li><br />
		<br />

		<li>If your input sounds are in the <b>.mp3</b> format, 
		you will need to convert to <b>.wav</b> or <b>.aif</b> 
		using some other software before using the files in CDP.</li><br />
		<br />
  
		<li>We have tried to keep all the source soundfiles used for 
		the examples as <b>.wav</b> on PC and <b>.aiff</b> on MAC.  
		These sources are <b>snd1.wav</b>, <b>count.wav</b>, 
		<b>frogs3cdt.wav</b> and <b>trcdt.wav</b>.  <i>The results of CDP 
		processes have been converted to <b>.mp3</b> for playback 
		(including analysis files) to save on space for the sound examples.</i></li>
		</ul>
	<li><b>from the Internet</b> &#150; Download to hard disk</li><br />
	<br />

	<li><b>from audio CDs</b> &#150; audio or digital OUT from 
	your CD Player to soundcard audio or digital IN, recording 
	via a sound editor or other record program (such as CDP's 
	RECSF).</li>
	</ol>
The first two of these types of source sound are already in digital 
format (i.e., <b>.wav</b> or some other soundfile format).  They are 
therefore transferred to your computer's hard disk directly, without 
any change of format.  The third involves a recording process, for 
which you need recording software and a soundcard that can handle 
analogue to digital conversion (AtoD) if required.
</p>

<p>
<b>Sounds brought in by recording:</b>
	<ol>
	<li><b>from audio out (analogue) of a MIDI instrument</b> &#150; 
	audio out from these instruments is in analogue format.  The 
	record process involves connecting audio Out to soundcard audio 
	In, pressing <b>Record</b> and <b>Start</b> on your recording 
	software and then performing on the MIDI instrument.</li>
	<li><b>from recording via an analogue recorder</b> &#150; again, 
	audio Out on the recorder to audio In on the soundcard, then 
	<b>Record</b> and <b>Start</b> on your recording software and 
	pressing <b>Play</b> on your analogue recorder.</li><br />
	<br />

	<li><b>from recording via Minidisc (digital)</b> &#150; 
	although the recording is digital, output is anlogue, so 
	the transfer to hard disk is the same as with an analogue 
	recorder.</li>
	</ol>
</p>

<h3 id="EDITSOUNDS">Basic Editing</h3>

<p>
When recording is involved, there is inevitably unwanted noise or silence 
at the beginning and end of the recording, due to the time delay between 
pressing <b>Record</b> and <b>Start</b> on your recording software and 
actually starting to perform or play back the sound.  Two types of edit 
are therefore in order to tidy this up:  CUT and DOVETAIL.
	<ul>
	<li>CUT removes a block of unwanted material or Saves only the 
	portion that you want, depending on how the software works.  CDP 
	SFEDIT CUT does the latter.  Many commercial editing programs, 
	such as <i>Cool Edit Pro</i> (now <i>Audition</i>), <i>Sound 
	Forge</i>, etc., do the former, blocking out the section 
	graphically.</li><br />
	<br />
	<li>In <i>Soundshaper</i> there is a <b>Play From - To</b> option.
	<IMG SRC="images/ssplayfromto.gif" vspace="10" align="center" 
	ALT="[Soundshaper Play To-From]"></a><br clear>
	It is easy to use this to find edit points aurally.  Then, when you 
	go to SFEDIT CUT, you will find these time points already in place 
	in the dialogue box.  This actually works rather well, as the 
	ears are a good judge of where to cut.</li><br />
	<br />
	<li>DOVETAIL smooths the beginning and end of the sound's amplitude 
	envelope, which can often be sudden or have a click after the CUT 
	process.  This can also be done in the soundfile editing program, 
	or with CDP's ENVEL DOVETAIL.  You can usually do this in your 
	recording software, but there are also CDP functions to handle 
	this.
		<ul>
		<li>The smoothing is handled by setting <i>times</i> in seconds, 
		i.e., how long from silence to full amplitude and <i>v.vs.</i></li>
		<li>These lengths are often determined by the purpose for which 
		the sound is to be used: e.g., just a bit so there is no click 
		and it gets to full amplitude as soon as possible (such as 0.01), 
		or longer times to achieve increasingly smooth crescendo and 
		decrescendo of the sound (such as attack times of 0.1 or 0.25 
		or 0.5 or 1.0 etc.).  Longer times significantly change sounds 
		which have a sharp, strong attack, softening or even disguising 
		them.  Thus DOVETAIL has a sound transformation aspect as 
		well.</li><br />
		<br />
		<li>CDP's DOVETAIL also has a Mode <b>2</b> in which an 
		<a href="../../html/glosstec.htm#EXPONENTIALCURVE"><b>exponential</b></a> 
		rather than a <a href="../../html/glosstec.htm#LINEAR"><b>linear</b></a> 
		slope is used.  This means that the rise to and fall from 
		full amplitude speeds up &#47; slows down.  This can be a 
		more effective way to remove clicks at the start and finish, 
		as the linear curve is sometimes too gradual to remove all 
		of the signal.</li><br />
		<br />
		<li>In <i>Soundshaper</i> you can double-click
		on the output cell to return to ENVEL DOVETAIL and use different values.  		(If you have saved the previous output soundfile, you can normally save the 		revised output to the same name again.)</li>
		</ul>
	</ul>
</p>

<p>
Sometimes the recording can have an undesirable level of noise on it, either 
from a poor quality sample, or from your own field recording.  This situation 
can often be improved by a using CLEAN function, often found in the sound 
editing software.  CDP's SPEC CLEAN (among the <b>Spectral Utils</b>) does 
this by a comparison method.
	<ul>
	<li>This is a Spectral Domain operation, so all files involved are 
	analysis files.</li><br />
	<br />
	<li>First take note of where some noise signal is located and CUT 
	out a (small) portion, retaining it for use as the <i>comparison 
	file</i> (referred to as <i>nfile</i> or <i>noisefile</i> in the 
	usage or dialogue box.</li><br />
	<br />
	<li>If you are sure that the noise signal will still be there (e.g, 
	there is some in the middle of the sound), you could do your CUT 
	and DOVETAIL operations first, and then use SPEC CUT in the Spectral 
	Domain, i.e., on the analysis file.</li><br />
	<br />
	<li>Mode <b>2</b> ('anywhere') appears to be effective in most 
	situations.  The software compares the signal of the <i>infile</i> 
	with that of the <i>noisefile</i>.  When an analysis channel's signal 
	level in the <i>infile</i> falls below that in the <i>noisefile</i>, 
	it means that the <i>infile</i> signal belongs to the noise aspect 
	of the sound, so that channels ia removed, hopefully removing most 
	of the noise with it.</li><br />
	<br />
	<li>The cleaned analysis file is then resynthesised and it is ready 
	to be used.</li><br />
	<br />
	</ul>
</p>

<p>
Two more types of basic editing may have a role in the early stages of 
preparing a sound for transformation processing:  PASTE, SPLICE.
	<ul>
	<li>PASTE is when all or part of a sound is inserted somewhere 
	in the middle of another sound.  This can be CUT and PASTE 
	operation in a graphic sound editor, or CDP's SFEDIT INSERT	
	can be used, specifying the time at which you would like the 
	new sound to be inserted.  The software smooths over the joins 
	(splices).  Too short a splice can result in a click or sudden 
	change of level, and too long a splice can result in an audible 
	dip in level at the point of join.  So it may take a few trys to 
	get it right if the level differences of the sounds cause 
	problems.</li><br />
	<br />
	<li>SPLICE (CDP's JOIN) involves joining whole soundfiles end to 
	end.  The same advice about the length of the splice window 
	applies.  If it is impossible to avoid an undersirable dip in 
	the level of signal, you may have to use a MIX operation, which 
	enables you to overlap the sounds.</li><br />
	<br />
	<li>Note that 3 new functions in Release 5 extend your options 
	regarding SPLICE operations: <a href="../../html/filestxt.htm#JOINDYNFILES">
	JOINDYN</a>, <a href="../../html/filestxt.htm#JOINSEQFILES">JOINSEQ</a> 
	and <a href="../../html/filestxt.htm#SEQUENCE2FILES">SEQUENCE2</a>.  
	These enable you not only list several soundfiles to join 
	together, but also enable you to specify a pattern (with 
	soundfiles repeated).  The links above take you to the information 
	about them in <i>CDP File Formats</i>.</li><br />
	<br />
	<li>PASTE (INSERT) and SPLICE may at times be used at this stage 
	in order <i>to create a soundfile with much change and contrast 
	in it</i>.  Then transformations that stretch out or extend 
	(lengthen) the sound can be more interesting and <i>create good 
	transition material</i>.  Some transformations of this nature 
	include BRASSAGE (also see the graphic version, <i>GrainMill</i>) 
	granular manipulations when higher <i>timestretch</i> values are 
	used, DISTORT REPEAT, or any of the functions in the EXTEND 
	Group.</li>
	</ul>
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP2">Step 2: Hearing Something: PLAY</h2>

<blockquote>
<p>
Installation includes setting up your directory for sounds.  This is 
very likely to be a project-related directory.  You need to have 
open this directory in order to access the sounds you want to hear.  
Within this HTML file we can play our main source sound, 
<a href="snd1.wav"><b>snd1.wav</b></a>  It is made from a single 
stroke on a brass gong, with dovetailed versions backwards and 
forwards mixed, and time-varying vibrato added to the result.
	<ul>
	<li>In <i>Sound Loom</i> you use the <b>Find Directory</b> button 
	and then <b>Any Directory</b> &#150; you can then browse for 
	and <b>Select</b> the required directory.  <b>List Named 
	Directory</b> places the contents of that directory in the 
	Window on the far right hand side of the display.  You then 
	<b>Grab</b> (cursor-selected files) and <b>Use on Workspace</b> 
	and then select a soundfile and click on <b>Play</b>.</li><br />


	<li>In <i>Soundshaper</i> you set your sounds directory on the 
	configuration page under OPTIONS/SETTINGS.  Your configuration 
	file can be a <b>Default</b> opened whenever you load 
	<i>Soundshaper</i>, or it can be a <b>Personal</b> one (e.g., 
	for a specific project) that you open under the FILE menu in the 
	top left corner of the OPTIONS/SETTINGS page.  Once the directory 
	is active, you can open it to select a soundfile to play either 
	via the FILE menu, or using the Icon to the left of the Play 
	transport.  Having selected the soundfile, you click on the Green 
	Button to Play.</li><br />


	<li><b>Creating analysis files</b> &#150; 
	<a href="../../html/filestxt.htm#ANALYSISFILES">
	<b>analysis files</b></a> are created from sound files, using the 
	Fast Fourier Transform (FFT) to change <i>time amplitude</i> data 
	to <i>frequency amplitude</i>.  You can <b>Play</b> these files 
	via a program created by Richard Dobson, called PVPLAY.EXE.  This 
	can be used on the command line.  <i>Soundshaper</i> calls it 
	automatically when you click on the Play button while an analysis 
	file is open, or you can access it via the TOOLS menu.</li><br />


	<li>Analysis files may be played directly (i.e., without conversion to 
	Time-Domain soundfile format) with PVPLAY.</li>
<!--
	<li><b>Troubleshooting</b> &#150; in case of difficulties, you may find 
	solutions in our <a href="../../html/cdptshoot.htm"><b>troubleshooting 
	document</b></a> (not yet available).</li>
-->
	</ul>
</p>

<p>
<b>IMPORTANT:</b><br />
Two contrasting sounds are used as sources for the examples below.  The first 
is our <b>snd1.wav</b> gong sound, but could be a more complex, noisy sound.  
The second should be something distinctly rhythmic, and we are using the 
chirrups of frogs sound, <b>frogs3cdt.wav</b>.  Please bear this in mind 
if you recreate these examples with your own sounds.  If you then 
follow the recommended names as you work through the examples, you 
will be able to play your results directly from this Tutorial, as 
well as from <i>Soundshaper</i> or <i>Sound Loom</i>.
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP3">Step 3: First Simple Function: Transposition</h2>

<blockquote>
<p>
OK, we can make our first alteration to a sound using the program 
MODIFY SPEED.  This will be a straightforward transposition (change 
of pitch level) up or down in the <a href="../../html/glosstec.htm#TIMEDOMAIN">
<b>time domain</b></a>.
	<ul>
 	<li><b>Access the function</b> (note this basic procedure when 
	using the respective GUIs):
		<ul>
		<li>In <i>Soundshaper</i>: go to the <b>Soundfiles</b> menu 
		(for Time Domain functions), then <b>Pitch &#150; Speed&#47;Transpose</b>.
		<br /><br /></li>
		<li>In <i>Sound Loom</i>: having Grabbed a file and put it 
		on the Workspace, then click on <b>Enter Chosen Files 
		Mode</b> and then on the sound you want to process (this 
		'chooses' it and places it in the left hand Processing 
		window.  Now click on the <b>Process</b> button to 
		access the list of functions.  Select 
		<b>Pitch: speed-pitch-tape transposition by semitones</b>.
		<br /><br /></li>
		<li>In command line mode:  enter the groupname followed by 
		the function name to get the usage, e.g., in this case, 
		<b>modify speed</b>.  The usage gives you a reminder of 
		what to do.  Then backtrack using the command history 
		function (DOSkey) and fill in the rest of the command 
		line.  The command line for this first process would be<br /> 
		<br /><code>modify speed 2 snd1 snd1d12 -12</code><br /><br /> 
		meaning call MODIFY SPEED, use Mode <b>2</b> (i.e., transposition 
		in semitones), input <b>snd1.wav</b>, name the output 
		<b>snd1d12.wav</b> and give <b>-12</b> as the 
		amount of transposition: down 12 semitones.  Even though 
		we would most often use the graphic user interface, we 
		can see that this text entry of the information is 
		actually very straightforward.</li>
		</ul>
	</li>
	<br />
	<li><b>Enter a transposition value</b> in number of semitones. 
	First try an octave lower, preceding the value with a minus 
	sign for a downwards transposition:  <b>-12</b>.<br />
	<IMG SRC="images/ssmspeedd12.gif" vspace="10" 
	ALT="Soundshaper MODIFY SPEED parameter box]"></a><br clear>
	This process lowers the whole sound.  Note that <b>fractional values 
	can be used</b> to create mictrotonal transpositions, e.g., 
	-1.5 lowers it 1&#189; semitones, = 150 cents.</li><br />
	<br />

	<li><b><i>Soundshaper</i></b>: <b>Run</b> the function (click OK), and <b>Play</b> it (to check the results), then <b>Save</b> (using the SAVE TO dialog, File > SaveAs, or the Toolbar Save icon).  Until you do this, only a temporary file is made.  
	<blockquote>
	<font color="#FF0000"><b>Recommendation:</b> to create file names that 
	tell you how the file was made: </b>type 'u' (for upwards transposition) or 'd' (for downwards transposition) and then the number of semitones.  Thus 
	the filename for our first sound transformation would become 
	<b>snd1d12</b>.  The <b>.wav</b> (or <b>.aif</b>) extension is 
	added automatically.  <b>NB: To save space, the examples distributed 
	with this Tutorial have been converted to </b>.mp3<b> format, while 
	the source files have been retained in </b>.wav<b> format, to make 
	it easier for you to use them for your own trials.</font>
	</blockquote>
	</li><br />
	<br />

	<li><b><i>Sound Loom</i></b>: <b>Run</b> the function and <b>Play</b> 
	(to check the results), then <b>Save</b>, naming 'u' or 'd' and 
	the number of semitones as described above.  Until you do this, 
	only a temporary file (which gets overwritten) is made.</li><br />
	<br />

 	<li>Also see the <a href="../../html/notechrt.htm"><b>Chart of Equivalent 
	Pitch Notations</b></a> and the <b>Transposition Ratios Chart</b> if you 
	need to count how many semitones a certain transposition entails.</li><br />
	<br />

	<li>Now we can PLAY our <a href="snd1.wav"><b>original</b></a> 
	(<b>snd1.wav</b>) and our <a href="snd1d12.mp3"><b>transposed</b></a> 
	(<b>snd1d12.mp3</b>) sounds and compare how they differ.
	</li>
	</ul>
</p>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP4">Step 4: Creating and Using Time Contours</h2>

<blockquote>
<p>
<b>Step 4</b> includes:
	<ul>
	<li><a href="#INTRO4"><b>Introduction</b></a></li>
	<li><a href="#TVTRANSPOSITION"><b>Time-varying Transposition</b></a></li>
	<li><a href="#GRAPHICBP"><b>Graphic Breakpoint Editor</b></a></li>
	<li><a href="#INSTANT"><b>Instant Changes</b></a></li>
	<li><a href="#RANDOMISED"><b>Randomised Values</b></a></li>
	</ul>
</p>

<h3 id="INTRO4">Introduction</h3>

<p>
 Time contours are a way of getting the sonic material to alter in 
some way during a given period of time.  This is an essential 
feature of all good music, as shown by the way a performer is 
constantly altering pressure of lips, breath or bow etc. to 
create a 'living' tone.  (These performing techniques are 
called <a href="../../html/glossmus.htm#ARTICULATION"><b>articulation</b></a>.)
</p>

<p>
Change over time is also referred to as 
<a href="../../html/filestxt.htm#BREAKPOINTFILES"><b>breakpoint files</b></a>.  
These contain a series of times and values to be used at those 
times:  because the values change, they 'break' the prevailing 
flow and cause it to change direction.  This is also referred to as 
'automation' because the breakpoint files apply the changes 
automatically during the processing of the sound.  In CDP, these 
files are saved as editable text files.  They can be 
created by text input (directly in a <i>Soundshaper</i> window or 
with a text editor), or by means of a graphic editor, which then 
writes the text breakpoint file as its output.
</p>

<h3 id="TVTRANSPOSITION">EXAMPLE: Time-varying transposition 
with MODIFY SPEED</h3>

<p>
<b>An essential piece of information about breakpoint files in 
CDP is that they <i>interpolate between (different) values</i></b>.  
What does this mean?  Consider the following breakpoint file that 
transposes an input sound 12.6 seconds in length (you may have to 
adjust the 12.6 to the actual duration of your <b>snd1.wav</b>):
<pre>
0      0
12.6  12
</pre>
The column on the left comprises <i>times</i>, that on the right 
comprises <i>values</i>, in this case, the number of semitones by 
which to transpose the sound.  Thus we have:
	<ul>
	<li>At time 0, transpose by 0 semitones (i.e., no 
	transposition)</li>
	<li>At time 12.6 seconds, transpose by up 12 semitones 
	&#150; upwards because it is a positive rather than negative 
	number.  A negative number transposes downwards.</li>
	</ul>
Thus the output sound will start at its original pitch (no transposition) 
and end 1 octave higher (12 semitones).  There are no values in the file 
inbetween these points, so the CDP software <i>interpolates</i>, i.e., 
creates a <i>series of intermediate values</i> inbetween 0 and 12 
semitones higher, spreading them out over the 12.6 seconds.  
<b>In other words, as we shall hear, it creates a glissando, as we 
can see with a diagram of the breakpoint file (<i>Sound Loom</i> 
Editor):</b><br />
<div>
<b><i>Sound Loom</i> graphic breakpoint editor, showing a glissando</b><br />
<a href="images/slglissbrk.gif"><IMG SRC="images/slglissbrkthumb.gif" vspace="10" hspace="5" 
ALT="[diagram of a glissando]"><br />View Fullsize</a>
</div>
</p>

<p>
<b>Here are the steps to do this in <i>Soundshaper</i>, entering the data 
as text:</b>
	<ol>
	<li>select, open and play an input soundfile, noting its length</li>
	<li>Access the function: <b>Soundfiles &#150; Pitch &#150; Speed&#47;Transpose</b> 
	</li>
	<li>Now we see the dialogue box where we can enter the number of 
	semitones.  This time we click on <b>T-V</b>, and when we 
	do, a new window appears in which we can write our breakpoint 
	file: <br />
	<IMG SRC="images/ss12&6u12.gif" vspace="10" 
	ALT="[Soundshaper MODIFY SPEED parameter entry]"></a><br clear>
	If this is already populated with a default file, either click CLEAR or simply delete some or all of the entries.</li>
	<li>We need to SAVE the revised text file:
		<ul>
		<li>Click SAVE AS and save to a new name: <b>ss12&6u12.brk</b>.<br>
		The program selects a dedicated folder for SPEED by default, but you can navigate to a different folder if you wish. </li>
		<li><b>N.B.</b> Do not click SAVE unless you intend to overwrite the default file <i>transposn.brk</i>. </li>
		<li>We could also go to the FILE menu (top left corner) 
		and select <b>Save Data File AS</b>, which will 
		prompt us to enter the name we want to use.
		<blockquote>
		<b><font color="#FF0000">Recommendation:</b> when 
		creating several breakpoint files for the parameters of 
		one complex function, <i>code the starting letters of the 
		names alphabetically</i> so that they will appear 
		next to each other in file listings.</font>
		</blockquote>
		</li>
		<li>Now click on OK to RUN the transposition process and save the output file as before. If we call it <a href="snd1tvtr.mp3"><b>snd1tvtr.mp3</b></a>, the name itself tells us that we used a breakpoint file to modify <b>snd1.wav</b>.</li>
		</ul>
	</ol>
</p>

<p>
<b>Here are the steps to do this in <i>Sound Loom</i>:</b>
	<ol>
	<li>We assume that you have listed a directory with your sounds, 
	selected your sounds and used GRAB to move them to the Workspace.</li>
	<li>Now enter Chosen Files Mode and click on <b>snd1.wav</b>.  It 
	will now pop in the window on the far left, meaning that it is 
	available for processing.</li><br />
	<br />

	<li>Now we click on the PROCESS button and then select MODIFY SPEED 
	among the highlighted buttons in the Time Domain group of functions.</li><br />
	<br />

	<li>As with <i>Soundshaper</i>, the dialogue box is very simple, and we 
	can enter our time-varying data as text or graphically.  The image 
	below shows the dialogue box with the constant value '-12' entered. 
	<IMG SRC="images/slmspeedd12.gif" vspace="10" 
	ALT="[Sound Loom MODIFY SPEED paramter entry]"></a><br clear>
	So we click on <b>Make File</b> to create a new time-varying breakpoint 
	file.  We see the 'Work on Text' or 'Work on Graph' option.  In this 
	case, we select 'Text'.
	<IMG SRC="images/sltextorgraphic.gif" vspace="10" hspace="10" ALT="[Text or 
	graphic data entry"]></a><br clear>
	Having clicked on 'Text', a window for text entry opens and we enter 
	our times and values.  The <i>Soundshaper</i> file went up, so let's 
	go down in this one.
	<IMG SRC="images/sl12-6d12text.gif" vspace="10" hspace="10" ALT="[Text entry in 
	Sound Loom]"></a><br clear>
	Having made it, please <b>name</b> it <b>sl12-6d12</b> (a <b>.txt</b> 
	extension is automatically added), <b>Save</b> it.  The dialogue box 
	returns, with the name of our new breakpoint file shown in the parameter 
	box.<br /></li><br />
	<br />

	<li>The next step is to click on RUN, and on OK when processing is 
	finished.  (If by any chance the processing fails, do not click on 
	ABORT, but on OK.)</li><br />
	<br />

	<li>Now we can PLAY the result.  If it's OK, we SAVE it to a name 
	that reminds us what it is all about.  In this case, we name the 
	output <b>snd1d12.mp3</b>.</li>
	</ol>
</p>

<h3  id="GRAPHICBP">Creating a breakpoint file with a graphic editor</h3>

<p>
Using a text editor to create breakpoint files can be simple, quick, direct, 
and precise. It helps to start by working from a rough drawing of 
the shape, annotated with time-points and values.  You may prefer to 
work with a graphic breakpoint file editor, which is more directly 
visual and intuitive.  Also, the BRKEDIT program offers the possibility 
to create exponential and logarithmic curves, compare two different 
files at the same time (useful when creating maximum and minimum 
value contours for the same parameter), perform data reductions 
(e.g., on envelope files), and audition the shape created.
</p>

<p>
There are 3 different graphic breakpoint file editors available in CDP:  
the general purpose BRKEDIT program just mentioned (also called from 
within <i>GrainMill</i>), one in the <i>Sound Loom</i> GUI and one in 
the <i>Soundshaper</i> GUI.  Each has their own Reference Manual section, 
so I won't go into them all here.  Please note that only the <i>Sound 
Loom</i> is available on the Mac.</p>  
<p>
As an illustration, let's look at the <i>Soundshaper</i> editor, using the breakpoint file <b>ss12&6u12.brk</b>.  It's the one that goes up 12 semitones.<br />
	<div>
	<b>A breakpoint file in the <i>Soundshaper</i> Editor</b><br />
	<a href="images/sstvtr-a.gif"><IMG SRC="images/sstvtr-athumb.gif" vspace="10" 
	hspace="5" ALT="[breakpoint file in the Soundshaper editor]">
	<br />View Fullsize</a>
	</div><br />
	<ol>
	<li>On <i>Soundshaper's</i> parameter page, click on the <b>Edit</b> button.</li>
	<li>Then select <b>Open X</b> (this is X timescale and the full 
	Y scale, which leaves space to move the Y coordinate further 
	than it was before)</li>
	<li>Note the upward sloping line of the glissando, and the 
	<i>time value</i> list up at the top right</li>
	<li>Now go to the <b>Adjust Values</b> sliders at the bottom and 
	slide the Y slider to the left and watch the sloping line move 
	downwards, while the changing values appear in the top right 
	<i>time value</i> grid.</li>
	<IMG SRC="images/sstvtr-b.gif" vspace="10" ALT="[breakpoint file in 
	the Soundshaper editor]"></a><br clear></li>
	<li>If you want to save the result under a different name, go to the <b>File</b> menu and select <b>Save As</b>. Otherwise, just click OK and the file will be saved with your new values. (Note that the file returned to the parameter page is a temporary one; click SAVE AS on that page to overwrite your previous version, or to create a new file name.) 
	</li>
	</ol>
</p>

<h3 id="instant">Instant Changes in Breakpoint Files</h3>

<p>
Our next topic in this important section is <b>how to create instant 
changes in breakpoint files &#150; rather than gradual, interpolated, 
changes</b>.  To do this, we have to stop interpolation from happening. 
This is done by putting the same value at the beginning and end of a 
time period.  Thus, if we want our sound to stay at its original 
pitch level for 1 second and change instantly at the start of the 
next second, we would do this:
<pre>
0     0
0.99  0
1    12
</pre>
The sound stays the same from time 0 to time 0.99, and then jumps up an 
octave (12 semitones) at time 1 sec.  Now we can create a file that jumps 
up an octave at 1 second, down 2 octaves (i.e., an octave below its 
original pitch level) at time 2 sec. and returns to its original pitch 
level at time 3 sec., staying there until the end of the sound.
<pre>
<font color="#FF0000">[time value]</font>
0      0
0.99   0 <font color="#FF0000">(No change for 0.99 sec)</font>
1     12 <font color="#FF0000">(Instant leap up 1 octave)</font>
1.99  12 <font color="#FF0000">(Steady pitch level for another second)</font>
2    -12 <font color="#FF0000">(Instantly down 2 octaves. NB not -24: the</font> 
2.99 -12 <font color="#FF0000">value is relative to the original pitch.)</font>
3      0 <font color="#FF0000">(Instantly back to the starting pitch level)</font>
4.5    0 <font color="#FF0000">(Where it stays for another 1&#189; sec)</font>
</pre>
</p>

<p>
We will do this again for our 12.6 sec. <b>snd1.wav</b> &#150; and mix instant 
and gradual changes.
<pre>
0.0   0
1.99  0
2.0   12
3.99  12
4.0  -12
7.00  0
7.99  0
8.0  -5
8.99 -5
9.00  16
12.0  0
</pre>
</p>

<p>
<div>
<b>Instant pitch changes in the <i>Sound Loom</i> graphic editor.</b><br />
<a href="images/sltvtr4-5.gif"><IMG SRC="images/sltvtr4-5thumb.gif" vspace="10" hspace="5" 
ALT="[diagram of breakpoint file with instant changes]">
<br clear>View Fullsize</a>
</div>
</p>

<p>
When we <b>Save</b> this file and click on <b>Use</b>, we return to the 
MODIFY SPEED dialogue box with this file in place.  After we <b>Run</b> 
this transposition process, we hear it <a href="snd1tvmixed.mp3"><b>jumping 
instantly up and down</b></a> and back again.  The times could be even closer 
together (e.g., 1.999) as long as they aren't the same:  two different values 
at the same time cannot be processed.
</p>

<p>
Perhaps you might now try creating some glissandos and instant 
transpositions with one of the graphic editors by adding points 
and moving them about.
</p>

<h3 id="RANDOMISED">Randomised Values</h3>

<p>
A final note about CDP breakpoint files:  <b>When a parameter such as 
pitch has upper and lower limits (max & min), the software's normal 
interpolating mode of operation causes it to select a value at 
random between these two limits &#150; or several values if in a 
multi-event context such as the TEXTURE Set</b>.
	<ul>
	<li>To use this randomisation process, just specify the 
	upper and lower limits (they are, therefore, 
	constants)</li><br />
	<br />
	<li>To restrict the output to one specific value, enter 
	the same value for both the upper and lower limits:  thus 
	all multi-events produced would be at the same value</li><br />
	<br />
	<li>To time-vary, enter time-varying contours (breakpoint files) 
	for the upper and lower limits.  Note that BRKEDIT, Richard Dobson's 
	graphic editor, enables you to open a previous breakpoint file 
	and display it in the background while creating a new one.  Thus 
	you can see exactly what you're doing when creating breakpoint 
	file pairs for upper and lower limits.  This editor also 
	enables you to create exponential and logarithmic curves as 
	well as linear shapes.</li>
	</ul>
</p>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP5">Step 5: Analysis &amp; Re-synthesis</h2>

<blockquote>
<p>
Deep into computer-based sound processing: working with analysis data
	<ul>
	<li><a href="#ANALYSIS"><b>Converting to Analysis Data</b></a></li>
	<li><a href="#PROCESSING"><b>Processing Analysis Data</b></a></li>
	<li><a href="#RESYNTHESIS"><b>Resynthesising Analysis Data</b></a></li>
	</ul>
</p>

<h3 id="ANALYSIS">Background: Analysis Data</h3>

<p>
Working with <i>frequency amplitude</i> 
<a href="../../html/filestxt.htm#ANALYSISFILES"><b>analysis files</b></a> opens 
up a vast area of sound processing only available via the computer.
	<ul>
	<li>The CDP Software has one of the, if not the, largest range 
	of functions which manipulate the data in FFT analysis files, 
	i.e., the frequency content and its amplitude &#150; also see 
	explanations of the <a href="../../html/glosstec.htm#TIMEDOMAIN">
	<b>Time Domain</b></a> and the <a href="../../html/glosstec.htm#SPECTRALDOMAIN">
	<b>Spectral Domain</b></a>.</li>
	<br />

	<li>What this means in practice is that a sound file 
	(<b>.wav</b> or <b>.aif</b>) has to be converted to an analysis 
	file (<b>.ana</b>) in order to be processed with these 
	functions.</li>
	<br />

	<li>To do this in <i>Soundshaper</i> we open a soundfile and 
	then go to <b>Spectral &#150; PVOC: FFT Convert</b> and select <b>ANALYSE</b>. 	Alternatively, you can just select a spectral process from the spectral menu and 	the program will automatically write the analysis file in the background (to the 	same name but with an <b>.ana</b> extension).</li>
	<br />

	<li>In <i>Sound Loom</i>, you need to set the system to use the 
	various CDP extensions.  This is done in <b>System State > ...</b>.  
	Otherwise it will have a <b>.wav</b> extension. If left like this, we 
	therefore suggest that you name the output with an 'ana' in the name.  
	Thus it could be: snd1ana.wav &#150; and then you can see from the name 
	that it is an analysis file.
	<IMG SRC="images/slpvocanal.gif" vspace="10" 
	ALT="[Sound Loom analysis dialogue box]"></a><br clear>
	</li>
	<br />

	<li>Note that you can play an analysis file using Richard Dobson's 
	PVPLAY.  In <i>Soundshaper</i>, this happens automatically when you 
	click on PLAY, or you can invoke PVPLAY (.ana files) in the 
	<b>Tools</b> menu.  Activate playback with e.g., the Spacebar.  
	Before this was available, you had to convert back to a soundfile 
	before you could hear it.</li>
	</ul>
</p>

<h3 id="PROCESSING">Processing Analysis Files</h3>

<p>
Processing an analysis file, from the user's point of view, 
is the same as processing a sound file.  Having created an analysis 
file, let's try out some functions.  Use the output of each 
of these as the input to the next one.
</p>

<p></b><a href= "../../html/cblur.htm#BLUR"><b>BLUR BLUR</b></a> 
(<i>Soundshaper</i> menu: <b>Spectral &#150; Time &#150; Blur</b>) &#150; 
The only parameter is the <i>number of windows to blur</i>.<br />
<IMG SRC="images/ssblur100.gif" vspace="10" ALT="[Blur parameter entry]"></a><br clear>
100 creates quite a lot of blurring, but not an extreme amount: the 
data in each group of 100 analysis windows is averaged.  Name the 
outfile in a way that reflects what you did, e.g., 
<b>snd1bl100.ana.</b>  Now <a href="snd1bl100.mp3">PLAY</b></a> 
<b>snd1bl100.ana</b> and listen to the difference.  If useful at this 
point in your work, eg., to process the file in the Time Domain, <b>Convert</b> 
back to a normal soundfile: 	SYNTHESISE <b>snd1bl100.ana</b> to form 
<b>snd1bl100.wav</b>.
<blockquote>
<font color="#FF0000">All <b>.ana</b> files are being converted to 
<b>.mp3</b> for these Tutorial examples: to save disk space and so 
that the Soundfile Player associated with your Browser can play 
them.  Therefore, even if it says 'snd1bl100.ana' as above, it will 
be an <b>.mp3</b> file in your folder.</font>
</blockquote>
</p>

<p>
<a href="../../html/cpitch.htm#TUNE"><b>PITCH TUNE</b></a> (<i>Soundshaper</i> menu: <b>Spectral &150; Freq/Pitch &150; Tune</b>) 
&#150; Select the MIDI pitches mode.  We need a file of MIDI pitches 
to define the chord to which we want to tune the sound, and the other 
parameters can be left as they are.  (The <a href="../../html/cpitch.htm#TUNE">
<b>Reference Manual</b></a> has detailed information about them.)  As 
we are in MIDI pitches mode, we just have to enter a series of 
<a href="../../html/notechrt.htm"><b>MIDI Note Values</b></a> representing our 
chord.  They should be in approximately the pitch range of the input 
sound and are better if spread out a bit rather than notes close together 
(think 'open position' chords).  E.g., a C'ish chord could be:  
<code>48 55 60 64 70 72 77</code>.
</p>

<p>
To enter this, we click in the <b>MIDI data window</b> to activate it 
and enter these values (either on one line with a space between each value or on separate lines)<br />
<IMG SRC="images/sstunempvs.gif" vspace="10" 
ALT="[Soundshaper: entering MIDI pitch values]"></a><br clear>
and then <b>Save Data File As</b> to your own name, e.g., <b>snd1.tun.</b>  We can give the output file a relevant name such as <b>snd1bl100tune.ana</b>. Click on OK to 
<b>Run</b> the process.  Note that this function introduces us to another type 
of auxiliary file used by the CDP functions.  See a list of them all 
in <a href="../../html/filesfrm.htm"><b>CDP Files &amp; Codes</b></a>, with 
further information and examples.
</p>

<p>
The blurred sound is now tuned to our specified chord, as, hopefully, will 
be clear when we <a href="snd1bl100tuneg.mp3">PLAY</a> it.  (You no longer need 
to convert to <b>.wav</b> first in <i>Sound Loom</i>.)  We lost some volume 
on this operation, so I've applied a <i>Gain</i> of 1.5, which is why the 
'g' is added to the name.
</p>

<p>
<a href="../../html/cstretch.htm#TIME">TIMESTRETCH</b></a> (<i>Soundshaper</i> menu: <b>Spectral &#150; Time &#150; Time-Stretch</b>) 
&#150; We can now stretch out the previous result, e.g., 3 times longer:  
just enter 3 as the <i>tstretch</i> factor and give a relevant output 
name, such as <i>snd1bl100tunegx3.ana</i>.<br />
<IMG SRC="images/ssstretchx2&3.gif" vspace="10" 
ALT="[Soundshaper timestretch dialogue box]"></a><br clear>
After applying <i>Gain</i> = 2, the result of our 3-part sound transformation 
sequence (BLUR &#43; TUNE &#43; STRETCH) now <a href="snd1bl100tunegx3g.mp3">
<b>opens out</b></a> the insides of the original sound.
</p>

<h3 id="RESYNTHESIS">Re-synthesis</h3>

<p>
Finally, to complete this section, we can RESYNTHESISE our final result 
and create a normal soundfile:  (<i>Soundshaper</i> menu: <b>Spectral &#150; 
PVOC  &#150; Synth</b>).  Now we have <i>snd1bl100tunx3.wav</i> in 
the input window and can <b>Play</b> it and perhaps carry on processing 
it with the <b>Time Domain</b> functions under <b>Soundfiles</b>.  Note 
how our filename encapsulates all of the sound transformation processes 
that we employed.  We can just look at this filename and see that it 
has been created by Blurring by a factor of 100 windows, Tuning it 
and Stretching it 2.3 times.  (This kind of naming convention is just a 
suggestion &#150; you will no doubt settle upon your own preferred method, 
that creates a distinctive name and helps you identify how you arrived 
at it.)
</p>

<p>
Saving <b>History</b> in <i>Soundshaper</i> also records everything done in that 
session, with all command lines and parameter values.  There is more information 
about <i>Soundshaper</i> History in the 
<a href="../../html/filestxt.htm#SSHISTORYFILES"><b>CDP Files &amp; Codes</b></a> 
document.
</p>

<p>
We now have now seen the main parts of the system:  Load and Play, 
a Time Domain function (Transposition), breakpoint files, Analysis, 
several Spectral Domain functions (Blur, Tune and Stretch Time), and 
Re-synthesis.  Now we are ready to explore other parts of the system 
quite quickly.
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2  id="STEP6">Step 6: Filter Banks</h2>

<blockquote>
<p>
Let us now return to our original <b>snd1.wav</b> and explore 
colouring the sound with different types of FILTER BANK and 
tuning it in a time-varying way with FILTER VARIABLE BANK.
</p>

<p>
<a href="../../html/cgrofilt.htm#BANK"><b>FILTER BANK</b></a> (<i>Soundshaper</i> menu: <b>Soundfiles &#150; Filter &#150; Bank</b>) 
&#150; Here we have a number of preset options (modes of the program) 
and several parameters.  Here we will use Mode <b>6</b>: 'equal 
intervals 2', which allows us to set the distance between filters in 
semitones.<br />
<IMG SRC="images/ssfbankeqint.gif" vspace="10" 
ALT="[Soundshaper FILTER BANK dialogue box]"></a><br clear>
<i>Q</i> is the bandwidth: the 'acuity' or 'tightness' of the filter.  
A low value 'lets through' more of the original sound, and a 
high value focuses the sound much more tightly on the center 
frequencies of the filter, creating 'resonance' or something 
akin to tuned pitches.  (I.e., this is a 'peaking' as opposed to 
a 'shelving' filter.)  Too high a <i>Q</i> may cause the sound 
to overload (amplitude distortion) or your speakers to ring.  
The filter process tends to reduce amplitude (because considerable 
parts of the sound are being filtered out), so some <i>Gain</i> is 
useful &#150; less when <i>Q</i> is high.  Let's try <i>Q</i> = 250 
and <i>Gain</i> = 20 on our original sound, selecting the <i>Equal 
Intervals 2</i> mode (Mode <b>6</b>) and setting the interval to 4 
(semitones).  <i>Double-filtering</i> tends to result in clearer, more 
focused pitches.  If not used and the <i>Q</i> is lower, more of the 
original sound comes through.  We also lower <i>low frquency</i> to 50 
for more bass.  The output soundfile could be named: 
<a href="snd1fbankeqint.mp3"><b>snd1fbankeqint.wav</b></a>.
</p>

<p>
Try this again with the <i>Subharmonic</i> Mode (using the original 
sound source).  In <i>Soundshaper</i>, double-click on the 'BANK' output cell,
 which take us right back to the FILTER BANK parameter page, 
with all the values previously selected still in place.  This time, we click on <i>Subharmonic</i>. We can leave <i>Q</i> at 150, reduce <i>Gain</i> to 5, and turn on 
<b>double-filtering</b> (which gives us a little chiff that isn't 
there without it).  The output, which we can name <a href="snd1fbsubh.mp3">
<b>snd1fbsubh.wav</b></a> is different from the equal intervals result!
</p>

<p>
<a href="../../html/cgrofilt.htm#VARIBANK"><b>FILTER VARIABLE-BANK</b></a> 
(<i>Soundshaper</i> menu: <b>Soundfiles &#150; Filter &#150; 
Varibank</b>) &#150; This function provides an effective way to 
tune sounds to specific harmonies.  It is similar to the Spectral 
functions <a href="cpitch.htm#TUNE"><b>PITCH TUNE</b></a> and especially 
<a href="cpitch.htm#TUNEVARY"><b>TUNEVARY</b></a>, enabling more than one chord to be used 
(quick changes or interpolating between chords as with transposition 
breakpoint files). Thus it 'harmonises' sounds with a great deal 
of flexibility regarding the chord defined, the number of chords, 
and the type of movement from one chord to the next (instant or 
interpolating).
</p>

<p>
<div>
<b><i>Soundshaper</i> Parameter page for FILTER VARIBANK</b><br />
<a href="images/ssvfbank1.gif"><IMG SRC="images/ssvfbank1thumb.gif" vspace="10" 
hspace="5" ALT="[Soundshaper FILTER VARIBANK parameter page]">
<br />View Fullsize</a><br clear>
</div>
</p>

<p>
The <b>data file</b> is written in separate lines:
<pre>
time1	note1 amp  note2 amp  note3 amp etc.
time2	note1 amp  note2 amp  note3 amp etc.
etc.
</pre>
</p>

<p>
A useful example file will be one that interpolates from chord 
1 to chord 2 (C-G-E-Bb-E-A to A-E-B-A-C#-A) over a given time period, 
then holds, and then changes instantly to a 3rd chord (B-G-B-G-B-F).  
Consult the <a href="../../html/notechrt.htm"><b>Equivalent Pitch 
Notations</b></a> chart to confirm exactly what pitches these 
Midi Note Values represent (use Mode <b>2</b> for MIDI):
<pre>
0.00	48 -3dB 55 -3dB 64 -3dB 70 -3dB 76 -3dB 81 -3dB
5.99	45 -3dB 52 -3dB 59 -3dB 69 -3dB 73 -3dB 79 -3dB
6.00	47 -3dB 55 -3dB 59 -3dB 67 -3dB 71 -3dB 77 -3dB
12.00	47 -3dB 55 -3dB 59 -3dB 67 -3dB 71 -3dB 77 -3dB
</pre>
If we want to hear the chords clearly, a rather high <i>Q</i> 
is needed (100), as well as some <i>Gain</i> (4)to compensate for all 
the filtering &#150; too much <i>Gain</i> will, however, cause 
resonance problems.  10 <i>Harmonics</i> are set to give it some 
edge, and <i>rolloff</i> is 0 to maintain harmonic richness.  
<b>Double-filtering</b> also strengthens the clarity of the pitches.  
When turned off, the chords weren't really formed.
</p>

<p>
We again use <b>snd1.wav</b> as the input.  The resultant output 
can be named: <a href="snd1vfb.mp3"><b>snd1vfb.wav</b></a>, 'vfb' 
standing for 'variable filter bank'.
</p>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP7">Step 7: Waveshape Distortion
</h2>

<blockquote>
<p>
Two of my favourite Waveshape Distortion functions are 
<a href="../../html/cdistort.htm#REPEAT"><b>DISTORT REPEAT</b></a> 
and <a href="../../html/cdistort.htm#SHUFFLE"><b>DISTORT SHUFFLE</b></a>.
</p>

<p>
<a href="../../html/cdistort.htm#REPEAT"><b>DISTORT REPEAT</b></a>  
(<i>Soundshaper</i> menu: <b>Soundfiles &#150; Distort 
cycles &#150; Repeat</b>) &#150; This function is very easy to use.  It 
has 3 parameters, of which the first two are essential.<br />
<IMG SRC="images/sldrepeat2-2.gif" vspace="10" 
ALT="[Sound Loom DISTORT REPEAT dialogue box]"></a><br clear>
<i>Cycles</i> specifies how many waveshapes to group together, 
i.e., more cycles mean a longer segment of input.  <i>Repeat</i> 
specifies how many times to repeat this group of cycles before 
moving on to the next group.  I suggest you start with the 
default (2 and 2), then try 5 repeats of 2 cycles, then 2 
repeats of 5 cycles, then anything you wish.  A relevant 
output name could be (carrying on from before):  
<a href="snd1dr2-2.mp3"><b>snd1dr2-2.wav</b></a>.
</p>

<p>
<a href="../../html/cdistort.htm#SHUFFLE"><b>DISTORT SHUFFLE</b></a>
 (<i>Soundshaper</i> menu: <b>Soundfiles &#150; Distort cycles &#150; Shuffle</b>) 
&#150; This is an immensely versatile function because 
the shuffle pattern can be varied enormously.  It has a <i>Domain</i> 
(source pattern) and an <i>Image</i> (shuffle pattern).<br />
<IMG SRC="images/ssdshuf.gif" vspace="10" 
ALT="[Soundshaper DISTORT SHUFFLE dialogue box]"></a><br clear>
The source pattern simply lists the elements to be shuffled, which 
can be few or many: e.g., <b>abcde</b>.  The shuffle pattern 
moves them about.  Repeating the same letter prolongs that part 
of the source, while mixing them up will jumble the source to a 
greater degree, moreso if the <b>Domain</b> is quite large.  This 
shuffle pattern first prolongs and then jumbles: 
<b>aabbccddeeaedbceaebecad</b>.  This is quite a long pattern about 56 
seconds), and if the Cycles parameter were set to 3, an even longer 
output length will be created.  This one might be called 
<a href="snd1dshuf.mp3"><b>snd1dshuf.wav</b></a>.
</p>

<p>
<i>CDP Files &amp; Codes</i> has more information about the 
<a href="../../html/filestxt.htm#SHUFFLECODES"><b>shuffle codes</b></a>.
</p>
</blockquote>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP8">Step 8: Moving Envelope Data Between Sound or Analysis Files
</h2>

<blockquote>
<p>
We now move into a very interesting part of the CDP Software:  
operations involving more than one file. 
	<ul>
	<li><a href="#WHATISENV"><b>Background</b></a></li>
	<li><a href="#TDAMP"><b>Time Domain Envelope Processing</b></a></li>
	<li><a href="#SDENV"><b>Spectral Envelope Processing</b></a></li>
	<li><a href="#SDFORMANTS"><b>Formants Processing</b></a></li>
	</ul>
We start by replacing the amplitude envelope of one file with that 
of another: ENVEL REPLACE, which operates in the Time Domain.
</p>

<h3 id="WHATISENV">Background</h3>

<p>
What is the <a href="../../html/glosstec.htm#ENVELOPE"><b>amplitude 
envelope</b></a>?  In the Time Domain, each sample 
data packet has a <i>time</i> and an <i>amplitude</i>.  If we graph 
these amplitudes as height and connect the tips of the lines, we 
get an amplitude contour: the amplitude envelope, i.e., the rise 
and fall in loudness.
</p>

<p>
The <a href="../../html/filestxt.htm#ENVELOPEFILES"><b>CDP Files &amp; 
Codes</b></a> document gives an example of an envelope file, 
with some further discussion about it.
</p>

<h3 id="TDAMP">Time Domain Amplitude Envelope Processing</h3>

<p>
<a href="../../html/cgroenvl.htm#REPLACE"><b>ENVEL REPLACE</b></a> (<i>Soundshaper</i> menu: <b>Soundfiles</b> #150; Envelope #150; Replace</b>)<br />
<IMG SRC="images/ssenvreplace.gif" vspace="10" 
ALT="[Soundshaper ENVELOPE REPLACE dialogue box]"></a><br clear>
The <i>window</i> parameter deals with the resolution of 
the envelope data: a low value for a fine, more accurate 
envelope, and a higher value for a coarser envelope.
</p>

<p>  
The <b>second</b> input is the <b>source</b> of the envelope 
and the <b>first</b> input is the <b>destination</b>, i.e., the 
sound <i>onto which</i> the envelope from the second input is 
imposed.
</p>

<p>
In a frog sound, we would hear the amplitude envelope very 
clearly as the <a href="frogs3cdt.wav"><b>separate chirps</b></a> 
of the frog.  If we <b>extract this shape and replace 
the more steady envelope</b> of our <a href="snd1.wav">
<b>snd1.wav</b></a> with it, <b>snd1.wav</b> will now 
<a href="snd1frogenv.mp3"><b>peak and ebb</b></a> with the 
separate chirp amplitude shapes of the frog.  This, therefore 
is an (amplitude) ENVELOPE REPLACE function.
</p>

<p>
ENVEL REPLACE can be put to good use in preparing a sound for a 
morph:  the sound is the same, but it moves like the second 
sound because it has acquired the second sound's amplitude 
envelope.  This can therefore be used as an intermediate 
stage between the first sound and the second sound of the 
morph:  <b>first sound <i>morphs towards</i> the 'first sound 
with the envelope of the second sound' <i>which then morphs 
towards</i> the second sound</b>, using two separate morph 
operations.
</p>

<p>
<a href="../../html/cgroenvl.htm#REPLACE"><b>ENVEL REPLACE</b></a> has several 
Modes that give you options to use envelopes acquired separately, 
or even envelopes hand-made by yourself.
</p>

<h3 id="SDENV">Spectral Domain Spectral Envelope Processing
</h3>

<p>
To understand <b>Envelope replacement in the Spectral Domain</b> 
we need to understand <a href="../../html/glosstec.htm#SPECTRALENVELOPE">
<b>spectral envelopes</b></a> in the first place, and why this involves 
<a href="../../html/glosstec.htm#FORMANTS"><b>formants</b></a>.
</p>

<p>
Secondly, we need to understand the options provided when we 
extract the spectral envelope, namely the <b>frequency-wise</b> 
or <b>pitch-wise</b> <a href="../../html/cformant.htm#extractformants">
<b>extraction methods</b></a>.

We are dealing with the spectral envelope, which is the <b>amplitude 
contour of the frequencies</b>.  Thus the nature of the sound itself is 
involved, its timbre, tonal qualities:  because different frequencies will 
have different amplitudes.  Thus, when we impose the amplitude contour 
<b>of the frequencies</b> in one sound on that of another, the 
<b>frequencies</b> of the <b>first sound</b> are emphasised with the 
result that the second sound now starts to sound like the first one 
&#150; <b>which still has its original overall Time Domain amplitude 
envelope</b>.  This process is traditionally known as 'cross-synthesis', 
and CDP refers to it as 'vocoding'.  The CDP vocode function is called 
<a href="../../html/cformant.htm#VOCODE"><b>FORMANTS VOCODE</b></a>.
</p>

<h3 id="SDFORMANTS">Spectral Domain Formants Processing
</h3>

<p>
<a href="../../html/cformant.htm#VOCODE"><b>FORMANTS VOCODE</b></a>  (<i>Soundshaper</i> menu: <b>Spectral #150; Morph&#47;Formants #150; Vocode</b>)
<IMG SRC="images/ssvocode.gif" vspace="10" 
ALT="[Soundshaper FORMANTS VOCODE dialogue box]"></a><br clear>
Now we can compare the difference when we take the 
spectral envelope (frequencies and their amplitudes &#47; timbre) from 
<b>count.ana</b> and impose them on <i>snd1.ana</i>.  
We name this output: <b>svocc.ana</b> and Convert it to 
<a href="svocc.mp3"><b>svocc.wav</b></a>.
</p>

<p>
Pitch extraction and combining with transposition files is a more 
advanced topic for a specialist workshop (the one on Transposition 
&amp; Shifting that is still 'in progress').
</p>
</blockquote>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP9">Step 9: Transitions &amp; Morphing
</h2>

<blockquote>
<p>
These are the topics introduced here:
	<ul>
	<li><a href="#INTRO9"><b>Background about Transition</b></a></li>
	<li><a href="#TDCROSSF"><b>Time Domain Amplitude Crossfade</b></a></li>
	<li><a href="#SDAMP"><b>Spectral Amplitude Crossfade</b></a></li>
	<li><a href="#ACHIEVING"><b>Achieving Audio Morphs</b></a></li>
	<li><a href="#OTHER9"><b>Other Transition Processes</b></a></li>
	</ul>
</p>

<h3 id="INTRO9">Background</h3>

<p>
Morphing is another advanced topic &#150; we only introduce it here, 
providing pointers towards relevant programs.  Gradual change is a 
basic musical process.  This time we are concerned with making a 
<b>transition</b> from one sound to another.  CDP has 5 programs 
directly related to this purpose:  SUBMIX CROSSFADE, COMBINE CROSS, 
MORPH BRIDGE, MORPH GLIDE and MORPH MORPH.
</p>

<p>
CDP's method for morphing is based on a timbral interpolation 
process.  There is another method which is based on partial tracking 
and replacement.  The latter is a good method to use with pitched 
sounds and is implemented in the public domain program, SNDAN, and 
in other commercial software packages.
</p>

<p>
A general suggestion is to allow plenty of time for an aural 
morph.  The ear is extremely sensitive to detail, but it takes time 
to notice and interpret what is going on.  Aural morphs cannot as 
a rule be anywhere near as fast as visual ones &#150; otherwise they 
just sound like quick crossfades.  Morphing is a process to explore 
and play with in a creative way, as suggested below regarding the 
creation of intermediate stages.  I often work with the second half 
of the first sound and the first half of the second, creating a 
suitable intermediate stage.  Then I morph from the first sound to 
the intermediate stage, and morph again from the result to the 
second sound.
</p>

<p>
<a href="../../html/cgromixr.htm#CROSSFADE"><b>SUBMIX CROSSFADE</b></a> is a mix operation in which the amplitude of the 
first sound gradually decreases as the amplitude of the second increases.  
This is quite different from a MORPH, which is a gradual (and weighted) 
interpolation from the spectrum (partials and their amplitudes) of one 
sound to that of another.  However, achieving a smooth and aurally 
effective 'morph' often involves more than a simple use of the program.  
It can easily be indistinguishable from a crossfade, without that 
sense of being distorted and reshaped as familiar with visual morphs.  
I suppose it depends on what you want to achieve.
</p>

<h3 id="TDCROSSF">Time Domain Amplitude Crossfade</h3>

<p>
In the <a href="../../html/glosstec.htm#TIMEDOMAIN"><b>Time Domain</b></a>, 
sample data is stored as <i>time</i> and <i>amplitude</i>.  SUBMIX CROSSFADE 
gradually reduces the amplitude values of the first sound to zero while 
gradually increasing the amplitudes of the second sound to zero.  
The result creates a smooth transition from the 
1<sup><small>st</small></sup> to the 2<sup><small>nd</small></sup>, 
but with no sense of an intermediate 'warped' stage as one may 
wish to have in an audio morph.  We can listen to our 
<a href="snd1.wav"><b>basic mix (snd1.wav)</b></a> make a 
<a href="snd1cffrogs.mp3"><b>transition</b></a> to <b>frog chirrups</b> 
in this way, a result very similar to that achieved by Spectral Domain 
amplitude crossover (next section).
</p>

<p>
<div>
<b><i>Soundshaper</i> SUBMIX CROSSFADE dialogue box</b><br />
<IMG SRC="images/sssubmixcf.gif" vspace="10" 
ALT="[Soundshaper SUBMIX CROSSFADE dialogue box]"></a><br clear>
</div><br />
SUBMIX CROSSFDADE also offers facilities to set the timing of the 
crossfade (<i>stagger</i> and <i>begin - end</i>), and in Mode <b>2</b> 
('Cosinusoidal') the <i>skew</i> of the crossfade.  Mode <b>1</b> is 
a Linear crossfade.
</p>

<h3 id="SDAMP">Spectral Domain Spectral Amplitude Crossover</h3>

<p>
A similar process in the Spectral Domain involves <b>replacing the 
channel amplitudes</b> of one file with those of another.  This is done 
with <a href="../../html/ccombine.htm#CROSS">COMBINE CROSS</a>.  Again, 
the amplitude data is taken from the <b>second</b> input and applied to 
the <b>first</b> input.  The effects vary depending on the weighting, i.e., 
the degree to which the frequency amplitudes of the second file are 
used.  This is controlled by the <i>interp</i> parameter:
	<ul>
	<li>With a weighting 0.25, we hear the first sound and practically 
	none of the second.</li>
	<li>With a weighting of 0.5, we hear both sounds equally.</li>
	<li>With a weighting of 0.75, we hear the second sound louder, 
	while the first sound sounds muffled.</li>
	<li><i>Interp</i> is a time-varying parameter with a range from 
	0 to 1.  1 is the Default, meaning that if you don't use it, 
	the second sound will dominate your result almost entirely.  On 
	the other hand, providing a breakpoint file that moves from 
	0 to 1 over the course of your sound will provide a smooth 
	transition from the first sound to the second sound.</li>
	</ul>

</p>

<p>
<a href="../../html/ccombine.htm#CROSS"><b>COMBINE CROSS</b></a> (<i>Soundshaper</i> menu: <b>Spectral-Morph&#47;Formants
-Cross</b>)<br />
<IMG SRC="images/ssspeccross.gif" vspace="10" 
ALT="[Soundshaper COMBINE CROSS dialogue box]"></a><br clear>
Our input sounds are both 12.6 seconds long (by design &#150; the 
frog sound was spliced 3 times and then cut to 12.6 seconds to match 
our other input.)  The weighting breakpoint file to make a smooth 
transition over this whole duration delays the beginning of the 
crossfade by 3 seconds:
<pre>
 0.0  0
 3.0  0
12.0  1
</pre>
We can name it <i>scrossfade.brk</i>. 
</p>

<p>
So we run COMBINE CROSS with this breakpoint file, entering 
<b>snd1.ana</b> as the first input and <b>frog3cdt.ana</b> as 
the second input (analysis files!).  In the <a href="speccrossfade.mp3">
<b>speccrossfade.ana</b></a>, the resultant sound, we hear what we 
expect: a smooth crossover from the first to the second: the 
frog gradually comes in and the gong sound gradually fade out.
</p>

<p>
The key thing to understand with this process is that the Spectral 
Domain holds the sonic data as <i>frequency</i> and <i>amplitude</i>.  
Therefore, the amplitudes involved are the <b>amplitudes of the 
frequencies</b>.  This is why the <i>sound</i>, the timbral 
qualities, of the second sound come through, not just its loudness 
as in the Time Domain, as we saw with ENVEL REPLACE and SUBMIX 
CROSSFADE.
</p>

<h3 id="ACHIEVING">Achieving Audio Morphs</h3>

<p>
If we assume that when we morph we expect to hear the first sound slowly 
changing into the second sound, then the emphasis is on the word 
'changing':  we want to hear the change as a process, we want to hear 
the second sound gradually assuming characteristics from the first 
sound, such as amplitude envelope, rhythmic features, and tonal 
characteristics.  Differences in pitch level can also pose 
challenges.  
</p>

<p>
One of the powerful features of the CDP software is the number of 
functions which can be brought to bear on morphing issues.  These can 
be used to create intermediate stages of a morph:
	<ul>
	<li><b>transposition functions</b> to adjust pitch levels (all 
	at once or with glissandi):  MODIFY SPEED, PITCH TRANSPOSE, 
	PITCH TRANSPOSEF (with formants preserved), PITCH OCTMOVE, 
	PITCH TRANSP, REPITCH COMBINE.</li><br />
	<br />

	<li><b>envelope functions</b> to introduce contours and 
	rhythmic features: ENVELOPE EXTRACT, ENVELOPE IMPOSE, ENVELOPE 
	REPLACE, ENVELOPE REPLOT or RESHAPE, FORMANTS VOCODE.</li><br />
	<br />

	<li><b>crossfade</b> or <b>channel amplitude replacement</b> 
	to move in a general way towards the second sound, and other 
	transition functions: SUBMIX CROSSFADE, COMBINE CROSS, 
	COMBINE DIFF, COMBINE MEAN, MORPH BRIDGE, and MORPH 
	GLIDE</li><br />
	<br />

	<li><b>blurring functions</b> to reduce the recognisability 
	of the first sound (as harmonic modulation first reduces 
	the harmonic identity of the first harmony): BLUR BLUR, 
	BLUR AVERAGE, BLUR SHUFFLE.</li><br />
	<br />

	<li><b>morphing</b> itself, which does the final timbral 
	interpolations: MORPH MORPH.</li>
	</ul>
</p>

<p>
Looking more deeply into creating an intermediate stage, let us consider 
three basic situations that relate to types of <i>infile</i>.
	<ol>
	<li><b>Vocode</b> &#150; the sounds are fairly different timbrally, 
	so that 'cross-synthesis' is used to transfer timbral qualities.  
	('Vocoding' in CDP is actually 'cross-synthesis' rather than 
	the harmonisation of sounds.)</li><br />
	<br />

	<li><b>Envelope transfer</b> &#150; one sound is rhythmic and one 
	is steady-state, so the rhythmic amplitude envelope is used to 
	put some contour into the steady-state sound.</li><br />
	<br />

	<li><b>transpose</b> &#150; the sounds are at different pitch levels 
	(but close enough to be viable for morphing).  In this case, it may 
	be useful to transpose the portion from the place where the morph will 
	begin, transposing the second file to glissando to the level of the 
	first file over the period of the morph.  But one has to be very 
	careful with speech, which is very sensitive to transposition.</li>
	</ol>
</p>

<p>
We can use vocoding as intermediate territory when morphing from 
<a href="snd1.wav"><b>our gong sound</b></a> to the <a href="count.wav">
<b>sound of a voice</b></a> counting from 1 to 10.  
Below is a typical hand-drawn rough sketch that maps out the morph.  
(Sketching out breakpoint files, morphs and mixes on paper can help 
to clarify objectives and procedures.)<br />
<div>
<IMG SRC="images/morphsketch.gif" vspace="10" 
ALT="[rough sketch of a morph]"></a><br clear>
</div>
This sketch shows the last two steps of a 3-step plan:
	<ol>
	<li><b>vocode</b> ('cross-synthesis') so that the sound of the voice enters 
	into the sound of the gong, forming <a href="svocc.mp3"><b>svocc.ana</b></a>.  
	We hear the voice counting, but the voice also resonates in an unusual way, 
	because it's now inside the gong, as it were.</li><br />
	<br />

	<li><b>morph</b> this vocoded sound with the count, forming 
	<a href="svocc-m-c.mp3"><b>svocc-m-c.ana</b></a>.  We hear the rough 
	voice, but it gradually gets clearer until, at the end, we hear the 
	original sound of the voice.  The morph starts after the beginning to 
	give some time with just the vocoded voice.
		<ul>
		<li><b>amplitude start and end</b>:  2.5 - 7</li>
		<li><b>frequency start and end</b>: 2.0 - 6.5 (sooner)</li>
		</ul>
	I tried some <i>stagger</i> to give more original voice at the end, but in 
	this case, it put the counting out of phase, so couldn't be used.</li><br />
	<br />

	<li><b>morph</b> the original gong sound with this morphed sound, 
	to form the beginning of the final result, so that the original gong sound 
	is heard on its own at the beginning.  This time we DO use some <i>stagger</i> 
	so that the original gong sound isn't muddled by the vocoded sound 
	at the beginning of the second file.  Note that the first sound, the 
	gong, is no longer heard after the end of the morph.  This sound 
	is cut off at this point, leaving only the second file, with the original 
	sound of the voice emerging out of the vocoded-morphed section.  The 
	final result is therefore <a href="snd1-m-svocc-m-c.mp3">
	<b>snd1-m-svocc-m-c.ana</b></a>, which we convert to a soundfile.</li>
	</ol>
</p>

<p>
Morphing is often done by starting both files at the same time.  The 
<i>stagger</i> parameter introduces some complication to this, especially 
if the files are not of equal length.
	<ul>
	<li><b>A. File1 is longer</b>
		<ol>
		<li>the shorter second file can start at the beginning.  When it 
		ends, <b>the first file will be cut off (truncated)</b>.</li><br />
		<br />

		<li>the shorter second file can be staggered so that it ends at 
		the same time as the first file, or after the first file ends.  
		The resultant file will be only as long as the second file (&#43; 
		plus any <i>stagger</i>).</li>
		</ol></li><br />
	<br />

	<li><b>B. File2 is longer</b> &#150; only the second file can be staggered, 
	so the resultant file will inevitably be longer than the first file.  The 
	shorter first file ends before the second (it ends when the morph ends), 
	but <b>the second will continue to its end</b>.  The resultant file length 
	will be the length of the second file &#43; any <i>stagger</i>.</li><br />
	<br />
	
	<li>It should be obvious that you cannot start the morph before the 
	second file comes in.  Therefore the start time of the morph must be 
	equal to or greater than <i>stagger</i>.</li>
	</ul>
Here is a diagram of these basic situations.  It is also found in the Reference 
Manual for <a href="../../html/cmorph.htm#MORPH"><b>MORPH MORPH</b></a>.
<div>
<IMG SRC="images/morphfilelens.gif" hspace="5" vspace="5" ALT="[chart summarising 
file lengths and morphing]"></a>
</div>
</p>

<h3 id="OTHER9">Other transition processes</h3>

<blockquote>
<p>
<a href="../../html/cmorph.htm#BRIDGE"><b>MORPH BRIDGE</b></a> operates like 
MORPH MORPH in that it is an interpolation 
process, but it moves from a time-specified fixed state in the first 
sound to a time-specified fixed state in the second sound, with various 
weighting options.  You can therefore choose parts of the sounds with 
specific timbral characteristics and explore the results.  The 
bridging process starts at the first time and ends at the second time, 
<b>interpolating all the sonic material inbetween these two points</b>.
</p>

<p>
<a href="../../html/cmorph.htm#GLIDE"><b>MORPH GLIDE</b></a> is similar to MORPH BRIDGE <b>except that it moves between 
fixed states that comprise only single windows</b>:  it interpolates 
between, shall we say, an interesting fragment of sound 1 and an 
interesting fragment of sound 2, using only these two windows and 
none of the sound material inbetween.  Given substantial differences 
between the two fragments, this can lead to wonderful gradual changes, 
especially if plenty of time is given:  the outfile length can be 
specified.  Don't be afraid to make it 30 or more seconds long.
</p>
</blockquote>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP10">Step 10: Assembly by Mixing or Algorithmic Scripting</h2>

<blockquote>
<p>
	<ul>
	<li><a href="#MIXCONCEPTS"><b>Different Approaches to Mixing</b></a></li>
	<li><a href="#SSMIXING"><b>Mixing with <i>Soundshaper</i></b></a></li>
	<li><a href="#SLMIXING"><b>Mixing with <i>Sound Loom</i></b></a></li>
	</ul>
</p>

<h3 id="MIXCONCEPTS">Different approaches to sonic assembly</h3>

<p>
Many if not most CDP users have a hybrid setup in which they assemble 
with their favoured audio sequencer.  These are designed as 'track-based' 
systems.  The standard use is to have the same sound repeat at different 
times on the same track, and to build up layers of tracks, each with their 
own sound.  You can also have different sounds on the same track.   
These systems are a great advance in musical assembly, are visually intuitive 
and are optimised for repeating and layered sounds.
</p>

<p>
From the point of view of sound composition, there are several things to 
watch out for when using an audio sequencer:
	<ul>
	<li>You have to be careful about how you handle variants of the same 
	sound, because within the virtual environment of the sequencer, the 
	original sound will be overwritten by the variant copies unless you 
	specify that you want to save it as a new sound.  This is especially 
	the case if you want to save these variants as separate soundfiles, 
	e.g., for use individually on a soundtrack.  In this case they will 
	have to be 'bounced' to hard disk to get them past their virtual status 
	to being an actual soundfile.</li><br />

	<li>Sounds cannot overlap on the same track without truncating the earlier 
	sound.  Overlapping is done by placing the sounds you want to overlap on 
	different tracks.</li><br />

	<li>A soundfile can be made from the whole sequence by a process called 
	'bouncing' or 'mixing down'.  This groups all the contents of the sequence 
	together into one file.  So you have to be careful when you mix lest you 
	group things that you could handle more flexibly if they were separate.</li>
	</ul>
</p>

<p>
Mixing can also be done within the CDP System.  CDP mixing ('Mixing with mixfiles') 
is optimised for creating complex sound objects.  You can add soundfiles (including 
repeats of the same sound) at any start time, so that file overlap is never a 
problem.  Sounds can be timed to come after one another or to overlap, but the 
thinking is more vertical than horizontal.
</p>

<p>
The main advantage of doing so is that it is good for building up complex 
musical passages in a controlled, step by step manner.  It is normal practice 
to mix groups of sounds at each significant stage of the construction process.  
Then these mixes are themselves mixed to create more complex or extended 
passages.  The emphasis is on the placement and layering of carefully designed 
sound objects that have been created by previous mixes.
</p>

<p>
The CDP 'Mix with mixfiles' process suffers from the lack of a graphic implementation.  
This is not as much of a disadvantage as it may seem, if the compositional focus 
is on 'sound objects' as described above.  In this case, CDP mixing is in fact 
very straightforward, and you don't run into some of the problems that can occur 
in the track-based systems designed to optimise more horizontally arranged sounds.  
The CDP mix process involves the creation of a text 'mixfile', either directly 
with a text editor, or via <i>Soundshaper</i> or <i>Sound Loom</i>.  These can 
be edited to 'tweak' your mix and saved as a way of documenting how you have 
achieved certain results.
</p>

<p>
<b>Rajmil Fischman's AL occupies a welcome middle ground</b>.  A fully graphic 
program (PC only), it enables you to copy and move sounds in both horizontal 
and vertical space, i.e., without the constraint of having separate tracks.  
This program was written thanks to an AHRB grant, is sent out with CDP Systems, 
and is available as a free download from 
<a href="http://www.keele.ac.uk/depts/mu/staff/Al/Al_software.htm">
<b>http://www.keele.ac.uk/depts/mu/staff/Al/Al_software.htm</b>
</a>.  Also see the <b>AL-ERWIN information page</b> on the CDP website.
</p>

<p>
CDP also has some rather interesting and advanced facilities that relate 
to the placement and overlap of sounds.  Chief of these is the TEXTURE SET, 
about which more in Section 11.  Other examples are the GRAIN programs, 
including BRASSAGE and <i>Grainmill</i> and the many different segmentation 
programs, such as EXTEND DRUNK (based on a Miller Puckette algorithm), 
BLUR SHUFFLE and DISTORT SHUFFLE.  We can also include the Release 5 
programs SFEDIT JOINDYN, SFEDIT JOINSEQ, EXTEND SEQUENCE and EXTEND 
SEQUENCE2.  These enable you to create multi-event musical passages 
by re-ordering a set of numbers, each number relating to an input 
soundfile.  &#150; All of these programs provide various ways to 
shape multi-event assemblies of sounds by specifying parameters 
in one program, rather than by assembling sounds one by one as in the 
standard mix procedure.
</p>

<p>
Finally, we should mention yet another approach to assembly.  This is to 
build scores using an algorithmic scripting language, such as 
Richard Orton's <i>Tabula Vigilans</i>.  Here we have a low-level 
musical programming language that can be used to design complex 
musical structures and&#47;or operate as a real-time (MIDI) instrument.  
I personally regard this (and similar programs) as one of the most 
important 21<sup><small>st</small></sup> century tools for moving 
computer music into design areas that push the boundaries of the 
computer and of music into new areas.  Although currently operating 
only with MIDI, it is possible to write a <i>Csound</i> score file 
with it, which is then used by <i>Csound</i> to create a musical 
passage using soundfiles.
</p>

<h3 id="SSMIXING">Mixing with <i>Soundshaper</i></h3>


<div>
<p><i>Soundshaper</i> has a dedicated Mix Page. Sounds are selected on the Main Page or on the Mix Page and are set up initially with dummy mix parameter values (corresponding to the CDP function <a href="../cgromixr.htm#DUMMY"><b>SUBMIX DUMMY</b></a>).

</p>

<b><i>Soundshaper</i> Mix Page, with completed mixfile</b><br />
<a href="images/ssmixpage.gif"><IMG SRC="images/ssmixpagethumb.gif" vspace="10" 
hspace="5" ALT="[Soundshaper Create Mix page]">
<br clear>View Fullsize</a><br />
</div>

<ol>
<li>Select a cell on the main page, containing a soundfile. Go to <b>Edit&#47;Mix : Mixfiles : Edit&#47;CreateMixfile</b>.  This takes you to the MIX page where the current cell's file is shown in the Soundfile List. To select others, click on the <b>Select Soundfile</b> button.</li>
<br />

<li>Click on a file in the Soundfile List. Its properties are shown (length, number of channels etc.) at the top of the page and you can audition it with the <b>Play</b> button there.</li>
<br />

<li>The sound's current mix parameters are shown in the <b>Mix Parameters</b> section.
Adjust values for Start time (when it should start to play), 
Level (how loud it is) and Pan (where it is to be located in the 
stereo field &#150; moving pans have to be applied to the sound 
before bringing it into the Mix Page).  Note that Level and Pan have 
to be applied for <b>each channel</b> if it's a stereo file:  select 
the channel and enter the values.  (Be careful to switch channels
 before entering the other channel's values.)  </li>
<br />

<li>Click on the <b>Add to List</b> button. The line you have just defined is displayed in the <b>Mix List</b> panel below the Parameters section.</li>
<br>

<li>To edit an item in the Mix List:
  <ul>
  <li>Double-click on the soundfile name in the Mix List to display its parameters again in Mix Parameters.  (Or click on the name, then the button <b>Edit Params</b>.) When you have finished editing, click the button <b>Update Item</b>. The highlighted item in the list is updated.</li>
  <li>Alternatively, for a simple edit, you can double-click on the item's parameters at the right of the Mix List; this opens up an editable text box.</li> 
 <li>Or you can re-select a soundfile in the Soundfile List, then after editing its parameters highlight the appropriate item in the Mix List and click <b>Update Item</b>.</li>
</ul>
</li>
<br>

<li>Select and add more soundfiles, as appropriate. You can select a soundfile more than once. Check your rough sketch to review file overlaps, which will indicate which files 
may need lower amplitude levels. </li><br />

<li>When everything is entered and adjusted, if you want to save the mix, optionally enter a name in the OUT Mixfile edit box and click on <b>File : Save Mixfile</b>. This step is not necessary unless you might want to access the mixfile at a later stage.</li><br />

<li>Click on the <b>MIX</b> button (top right corner) and the mix is performed, creating a soundfile. </li><br />

<li>If you do not need to see the mixfile list, particularly if you do not intend to use any of the infiles more than once in the mix, a quicker alternative procedure to the above is:
<br>  
  <ul>
  <li>Instead of Step 1, select <b>Edit&#47;Mix : Mix : Mix</b> on the Main Page. The current cell will be your first selected file. Now click on cells for other files, or select them via the file selector. These files are added to the ADD INPUT dialog; click OK in this box when finished. This takes you to the Mix Page, where your selected files are listed. Or you can select soundfiles on the Mix Page (click on the <b>Select Soundfile </b> button).</li>
  <li>Follow steps 2 and 3 above, re-selecting any sound in the Soundfile List as required, until you are satisfied with its parameter values. Click <b>MIX</b> to perform the mix.</li>
  </ul>
In this method, the Mix List is not shown and all of the files in the Soundfile List are mixed, but if you change your mind, you can select <b>Edit/Create Mixfile</b> in the Mixfile Operations list and then perform steps 5, 6 and 8 as above.
</li>
<br>

<!--   out of date: outfile is saved from Main Page after processing...
<li>Now tick <b>Mix with Mixfile</b> (top left part of the page) and enter 
your output filename.  I like to put an 'mx' somewhere in the name, usually 
at the end, to show that it is a mix.  I also prefer to give it a name 
very similar to the mixfile name, to show that they are connected.</li><br />
<br />
-->

<li>You may want to return to the mix after hearing it, in order to 
adjust make adjustments. 
  <ul>
<li>Double-click on the output cell (labelled 'MixEdit' or 'Mix'), or CTRL+ENTER if you prefer. If you do this right away, the Mix Page will appear as you left it. Edit the parameters as described above and click the <b>MIX</b> button.</li>
<li>If the Mix Page has been used for a different mix since your last edit, you can still recall and edit the earlier mix if you have saved it (Step 7). Select <b>File : Open Mixfile</b>. Note that the sounds listed in the Soundfile List will be those of the later mix, so ignore these or clear the list.</li>
  </ul>
</li>
</ol>

<h3 id="SLMIXING">Mixing with <i>Sound Loom</i></h3>

<p>
<div>
<b><i>Sound Loom</i> Initial MIX dialogue</b><br />
<a href="images/slmixpage.gif"><IMG SRC="images/slmixpagethumb.gif" vspace="10" 
hspace="5" ALT="[Sound Loom initial MIX dialogue]">
<br />View Fullsize</a><br clear>
</div>
</p>

<p>
The MIX procedure in <i>Sound Loom</i> is a little different, though also 
focused on creating the mixfile.  It uses the CHOOSE FILES mechanism to 
select the soundfiles to mix, then quickly creates a template mixfile 
using the soundfiles you have chosen.  You then edit the mixfile and run 
the mix.

<ol>
<li>Step 1 therefore is to select the directory containing the files for 
your project, that you will be mixing.  Appropriate files from this directory 
are GRABBED and moved to the Workspace.  You will probably have done all 
this as part of your work on the project up to this point.</li>
<br />

<li>Now you clear everything in the left panel and activate CHOOSE FILES.  
Now you select (on the Workspace) the files you are going to mix, and they 
are all placed in the left panel:  CHOSEN FILES.</li>
<br />

<li>In PROCESS you now go to <b>Mix &gt; Create Mixfile &gt; superimposed</b> 
(or 'end to end' if you want the start time of each soundfile in the mix 
template file to begin where the previous sound ends).  When you RUN this, 
a template mixfile is made:  it contains all the soundfiles, start times 
= 0 (for 'superimposed'), the number of channels for each sound, and default 
values for Level and Pan.  <b>Remember to SAVE this file</b>.</li>
<br />

<li>Now you go back to <b>Workspace, New Files</b>, clear the sounds in the 
left panel and select (CHOOSE FILES) the new template mixfile from the 
Workspace.</li>
<br />

<li>When you now go to PROCESS, select <b>Mix with Mixfile</b>.  You now 
need to select <b>Edit Mix</b>.  The screen below shows the edit window.
</p>

<p>
<div>
<b>Sound Loom Edit Mixfile Window</b><br />
<IMG SRC="images/slmixedit.gif" vspace="10" hspace="5" ALT="[Sound Loom Edit Mixfile 
dialogue]"></a><br clear>
</div>
	<ul>
	<li>click on 'Edit Mix' and edit the template mixfile with the start 
	times, levels and pan details that you want to have.  Remember that 
	moving pans have to be part of the soundfile before it reaches the 
	MIX stage.</li><br />
	<br />
	<li>When you click on 'Edited Version', your named template mixfile 
	is re-saved with your new edits.</li><br />
	<br />
	<li>Go to RUN and the MIX is performed.</li><br />
	<br />
	<li>Play and SAVE if OK.  Otherwise, go back to 'Edit Mix' etc.</li>
	</ul>
</li>
</ol>
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP11">Step 11: Multi-event Assembly with Texture</h2>

<blockquote>
<p>
This is a very powerful and important part of the CDP software.  
I have written an extensive <a href="../../html/cgrotext.htm"><b>Reference 
Manual</b></a> and prepared an optional <b>Texture Workshop CD-ROM</b>. 
I recommend these additional materials because the possibilities of the 
TEXTURE Set of programs are many and varied and there are many details to 
master in order to make use of them.  This section of our 'Getting Started' 
tutorial can only cover a few of the basics:
	<ul>
	<li><a href="#TXPARAMS"><b>Parameters</b></a></li>
	<li><a href="#TXNDF"><b>Note Data File</b></a></li>
	<li><a href="#TXTGRID"><b>Timing Grid</b></a></li>
	<li><a href="#TXHGRID"><b>Fixed Harmonic Grid</b></a></li>
	<li><a href="#TXCHGRID"><b>Changing Harmonic Grid</b></a></li>
	<li><a href="#TXMOTIFS"><b>Motifs</b></a></li>
	<li><a href="#TXNS"><b>Nodal Substructure &amp; motifs</b></a></li>
	<li><a href="#TXPLAY"><b>Play between Randomised &amp; Defined</b></a></li>
	</ul>
</p>

<h3 id="TXPARAMS">TEXTURE PARAMETERS</h3>

<p>
<b>The first key to the TEXTURE Set</b> is the parameter listing.  We can 
summarise these with first a screen of a TEXTURE SIMPLE dialogue box filled in for 
use with Mode 5 (random), and then an explanation of each parameter.
</p>

<p>
<div>
<b><i>Soundshaper</i> TEXTURE SIMPLE Dialogue Box</b><br />
<a href="images/txsimpledialogue.gif"><IMG SRC="images/txsimpledialoguethumb.gif" vspace="10" 
hspace="5" ALT="[Soundshaper TEXTURE SIMPLE dialogue]" >
<br />View Fullsize</a><br clear>
</div>
</p>

<p>
Using the gong sound as the input and <b>the above settings</b>, 
we produce a randomised texture, <a href="txsnd1.mp3"><b>txsnd1.wav</b></a>.  
Yes, it's a bit mad, but it shows a multi-event texture being formed and 
the fact that the randomised pitch selection between <i>minpitch</i> and 
<i>maxpitch</i> will include microtonal transpositions.
</p>

<p>
A quick overview of the main TEXTURE parameters follows.
	<ul>
	<li><b>outdur</b> &#150; the desired length of the <i>outfile</i>.  
	This will be a minimum length.  It is often longer because the 
	program tends to finish patterns that it has started.</li>
	<li><b>note data file</b> &#150; a text file containing various 
	components with which to shape the result</li>
	<li><b>packing</b> &#150; the time-density of note events</li>
	<li><b>scatter</b> &#150; timing offset for the <i>packing</i>, to 
	randomise or 'humanise' the results</li>
	<li><b>tgrid</b> &#150; a quantisation mechanism, set to 0 when not used</li>
	<li><b>soundfiles</b> &#150; the two fields here are usually filled 
	in with 1, meaning 1 soundfile input.  If there are, for example, 
	three input sounds, the first field will be '1' and the second 
	one will be '3'.</li>
	<li><b>loudness</b> &#150; MIDI 'velocity' Range 1 to 127</li>
	<li><b>duration</b> &#150; the length of each note event, each of which 
	starts <b>from the beginning of the <i>infile</i></b>.  When different 
	values are used for these two fields, a duration is randomly chosen 
	from somewhere between the two values.</li>
	<li><b>pitch</b> &#150; these fields are for minimum and maximum pitch 
	transpositions, given as MIDI Pitch Values relative to the reference 
	pitch.  If the reference pitch is 60 (Middle-C) and the two pitch 
	fields are both 60, then all note events will be on the same pitch.  
	If the minimum is 60 and the maximum is 67, the pitch transposition 
	for each note event will be randomly chosen somewhere inbetween, 
	including microtonal values.  Time-varying breakpoint files can be 
	used as well, which is very important.</li>
	<li><b>attenuation</b> &#150; gain reduction.  Use more if there will 
	be considerable overlap of a fairly loud sound.</li>
	<li><b>position</b> &#150; central position in horizontal stereo field 
	for <i>spread</i></li>
	<li><b>spread</b> &#150; amount of spread around <i>position</i>;  1 is 
	across the full stereo field</li>
	<li><b>use whole sound</b> &#150; disregard <i>duration</i> values and use 
	the whole of the input soundfile for each note event</li>
	<li><b>mult</b> &#150; if there is a <i>mult</i> parameter, this 
	controls <b>tempo</b>.  There are also Min and Max options, randomly 
	chosen values inbetween, or even time-varying breakpoint files.  1 = 
	same tempo, 2 = twice as fast, 0.5 is twice as slow.</li>
	</ul>
</p>

<h3 id="TXNDF">NOTE DATA FILE</h3>

<p>
<b>The second key to the TEXTURE Set</b> of programs is the 
<a href="../../html/filestxt.htm#TEXTURENDFFILES">
<b>note data file (ndf)</b></a> and its various components.  This is 
a text file that instructs the program with your wishes &#150; not 
all of them, but all of the more complex features.
</p>

<p>
The order in which the note data file components occur in the file 
varies with the different programs.  This formatting information is 
summarised in the <a href="../../html/ndfchart.htm"><b>TEXTURE Note 
Data File Chart</b></a>.  I recommend that you have a printout laminated 
for permanent use.  (I can't use TEXTURE without it!)
</p>

<p>
The following is a very simple note data file comprising the pitch 
reference and a two line harmonic set (used in Mode 3 of TEXTURE SIMPLE):
<pre>
60            <font color="#FF0000">MIDI reference pitch</font>
#2            <font color="#FF0000">number of lines in harmonic grid</font>
0 1 60 0 0    <font color="#FF0000">first line of grid, Middle-C</font>
0 1 67 0 0    <font color="#FF0000">second line of grid, the G above</font>
</pre>
	<ul>
	<li>The first line in all note data files contains a MIDI Pitch Value 
	as a reference pitch for (possible) transpositions for each note event 
	in the texture.  If you have more than one input soundfile, you need 
	separate values for each soundfile, e.g., 60 60).</li><br />
	<br />

	<li>Whatever value you give the reference pitch is taken by the software 
	to mean no transposition (i.e., it is taken to be the original 
	pitch level of the sound).  It is often impossible to determine a 
	precise pitch level for a complex, noisy sound, which is why this 
	s called a 'reference pitch'.  Pitch transpositions move the pitch 
	evel up or down the specified number of (possibly fractional) 
	semitones from this reference pitch.  Thus if you have the sound 
	of wind and give it an MPV of 60, if you tell the program to 
	transpose it to 72, it will move the sound of the wind up an 
	octave (12 semitones), and 48 will move it down an octave, etc.</li><br />
	<br />

	<li>When you use Mode 5 ('random'), you specify <i>minpitch</i> and 
	<i>maxpitch</i> values in the dialogue box (constant, i.e., just one 
	value, or a time-varying breakpoint file).  The program selects 
	a transposition for each note event that lies somewhere between 
	these limits, and note that this includes microtonal variants.  
	The latter can be useful when you want to create washes of sonic 
	material that do not have noticeably discrete pitches.</li><br />
	<br />

	<li>When you want all the note events to have the same pitch, 
	give the same MIDI Pitch Value to the Min and Max Pitch parameters.</li>
	</ul>
</p>

<h3 id="TXTGRID">TIMING GRID</h3>

<p>
Rhythms can be created with a <b>timing grid</b>, which is another component 
of the note data file.  Here we are using it independently with TEXTURE TIMED, 
but timing instructions can also be used within motifs (TEXTURE MOTIFS), 
together with motifs (TEXTURE TMOTIFS), or provided in the form of a 
nodal substructure (TEXTURE DECORATED and TEXTURE ORNATE program sets) 
&#150; see below.  
</p>

<p>
The format of the timing grid is shown in the following example:
<pre>
#5
0.00 1 0 0 0  <font color="#FF0000">dotted quaver</font>
0.75 1 0 0 0  <font color="#FF0000">semi-quaver</font>
1.00 1 0 0 0  <font color="#FF0000">dotted crotchet</font>
2.50 1 0 0 0  <font color="#FF0000">quaver</font>
3.00 1 0 0 0  <font color="#FF0000">crotchet if skiptime is 1</font>
</pre>
You can see that the <b>duration of the note event is determined by 
the next start time</b> (left column).
</p>

<p>
To work this out, you need to think of rhythms numerically, most easily 
by letting 1 = 1 sec. (i.e., MM crotchet = 60).  You can set the tempo 
with the <i>mult</i> parameter(s).  Thus a crotchet (&#188;-note) = 1, 
a quaver (<sup><small>1</small></sup>&#47;<sub><small>8</small></sub>
-note) = 0.5 etc.  Start at 0 and add the duration-value of the note to 
get the next start time.  It will overlap or leave a gap depending on the 
length of the <i>infile</i> or the <i>mindur maxdur</i> settings.
</p>

<p>
When used <b>independently</b>, the timing grid defines when pitches 
that are randomised between <i>minpitch</i> or <i>maxpitch</i> will occur.  
In other words, <b>the rhythmic 'riff' repeats, but the pitches are 
randomised.</b>  If a harmonic grid is used, then the pitches are randomly 
selected from the grid.
</p>

<p>
The timing grid above <a href="txsnd1timed.mp3"><b>repeats a rhythm</b></a> in  
a narrow pitch range:  <i>minpitch</i> = 60 and <i>maxpitch</i> = 64 (span 
of a Major 3<sup><small>rd</small></sup>).
</p>

<p>
<i>Skiptime</i> is an important parameter in this program.  The last note 
event in the timing grid <b>begins</b> at 3.00.  <i>Skiptime</i> defines the 
amount of time between the <b>start of this last note event and the repeat 
of the timing grid</b>, i.e., when it starts over with the note event at 
time 0.00.  In this case we put a 1, making it 1 second before the grid 
repeats.  If the tempo is made faster or slower, <i>skiptime</i> has to be 
adjusted accordingly.  The maths here is:  new_skiptime = old_skiptime * (60 
&divide; new_tempo).  E.g., at a new_tempo of 120, the 1 sec. <i>skiptime</i> above 
becomes 0.5 sec.: new_skiptime = 60 * (60 &divide; 120) = 0.5.
</p>

<h3 id="TXHGRID">FIXED HARMONIC GRID</h3>

<p>
Another common component of a note data file is a fixed harmonic grid.  
This is a great feature, because it enables you to link your texture to 
other harmonies used in your composition, whether clearly or subtly, 
depending on the nature of the sound, the rate of <i>packing</i>, 
the length of soundfile used for each note event, and similar considerations.  
<pre>
60            <font color="#FF0000">MIDI reference pitch</font>
#2            <font color="#FF0000">number of lines in harmonic grid</font>
0 1 60 0 0    <font color="#FF0000">first line of grid, Middle-C</font>
0 1 67 0 0    <font color="#FF0000">second line of grid, the G above</font>
</pre>
	<ul>
	<li>Two terms are used to describe these harmonic grids: 'Set' means 
	that only the pitch levels specified in your grid are used.  'Field' 
	means that the pitches may be taken from any octave.  'Fields' can 
	be useful when you want an open, spread out texture.</li><br />
	<br />

	<li>Through the use of this harmonic grid, the transpositions for 
	all the note events of the texture 'snap' to the pitch levels 
	specified, are restricted, 'constrained', to these pitch levels only.  
	Each note event will (randomly) select a pitch from this grid.</li><br />
	<br />

	<li>If the <i>packing</i> is tight (e.g., 0.05 sec.), the note events 
	will come thick and fast.  Thus, if the grid contains just two 
	MPVs spaced 7 semitones apart, e.g., 60 and 67, if the packing is fast 
	and the source sound is reasonably clearly pitched, 	you will hear a 
	<a href="txsnd1shimmer.mp3"><b>shimmering Perfect 
	5<sup><small>th</small></sup></b></a>
	because of the rapid multiple note events created.</li><br />
	<br />

	<li>Each harmonic grid is preceded by an indication of how many 
	lines it contains.  E.g., #2 means that it contains two lines.  If 
	there is a mismatch, you will get an error message.</li><br />
	<br />

	<li>The format for this grid is '0 1 MPV 0 0' for each line.  The first 
	column is the start time, and is always 0 if you want any of the pitches 
	to be selected at any time.  The '1' in the second column is always '1', 
	MPV means MIDI Pitch Value, and the last two columns are always 0 (these 
	fields are used for motifs).</li><br />
	<br />

	<li>I used the phrase 'all note events' because it is the usual case 
	that the <i>packing</i> rate will be faster than the time changes in 
	the harmonic grid.  This may give the 'shimmering' effect, but also 
	may create chords:  if you have several lines starting at the same time, 
	and then several more starting at a different time, and a fast 
	<i>packing</i> rate, then you will hear chords comprising all the 
	pitches with the same start time.  This is one of the uses of a 
	'changing harmonic grid', described in the next section.</li>
	</ul>
</p>

<h3 id="TXCHGRID">CHANGING HARMONIC GRID
</h3>

<p>
A variant on the harmonic grid is a 'changing harmonic grid'.  All of 
the texture programs contain this facility.
<pre>
60            <font color="#FF0000">MIDI reference pitch</font>
#3            <font color="#FF0000">3 lines in the harmonic grid</font>
 0 1 60 0 0   <font color="#FF0000">time 0, note events are on Middle-C</font>
 5 1 65 0 0   <font color="#FF0000">time 5, note events are on the F above</font>
10 1 67 0 0   <font color="#FF0000">time 10, note events are on the G above</font>
</pre>
	<ul>
	<li>Modes <b>2</b> ('Field') and <b>4</b> ('Set') are used when you want to 
	specify the time at which a particular pitch level is to come into play.  Thus 
	if as here line 1 were '<b>0</b> 1 60 0 0' and line 2 were '<b>5</b> 1 65 0 0', 
	all note events would be on Middle-C for 5 seconds (the count starts at 0), 
	and on the 5<sup><small>th</small></sup> second, all note events would 
	be on the F above Middle-C.  Smaller time changes can result in melodic 
	shapes, or even (tiny time changes) strumming effects.  <i>Packing</i> 
	and the length of <i>infile</i> employed make a big difference to the result.  
	You can notionally create clear melodic shapes with this program, but it 
	actually works better via the nodal substructure used in the DECORATED and 
	ORNATE sets (see below).</li><br />
	<br />

	<li>Our example will use a fairly slow <i>packing</i> (0.25) with a relatively  
	large <i>scatter</i> offset (0.1).  This will give us 
	<a href="txsnd1relaxed.mp3"><b>relaxed but irregular repetitions</b></a> of the 
	<i>infile</i> that move upwards on the pitches specified when the next time 
	point occurs.  Again, <i>mindur</i> and <i>maxdur</i> and 'use whole sound' 
	control the amount of <i>infile</i> used for each note event, and therefore 
	the amount of note event overlap.</li>
	</ul>
</p>

<h3 id="TXMOTIFS">MOTIFS</h3>

<p>
The MOTIFS and TMOTIFS Sets allow you to use motifs.  The 
note data file below shows a Mode <b>5</b> situation:  just the reference 
pitch and a motif definition.  Note that the two columns on the right 
are used:  <i>amplitude</i> (MIDI range) and <i>duration</i> (length of 
<i>infile</i> from its beginning to use &#150; legato overlaps are 
achieved by making the duration a little longer than the time to the 
next event.)  Because all the fields are used, I refer to these motifs 
as 'fully defined'.
<pre>
60
#5
0.0 1 60 64 1.0
0.5 1 65 74 1.0
1.0 1 67 84 2.0
2.5 1 63 74 1.0
3.0 1 65 78 2.5
</pre>
</p>

	<ul>
	<li>In TEXTURE MOTIFS, this motif is started on a pitch selected 
	at random between the <i>minpitch</i> and <i>maxpitch</i> parameters.  
	You can get some very complex pitch overlapping when event 
	density (<i>packing</i>) is less than the full length of your motif(s) 
	&#150; yes, you can have several!  Alternatively, you can make the 
	<i>packing</i> equal to or greater than the length of the motif.</li><br />
	<br />

	<li>Our first example <a href="txsnd1motif1.mp3"><b>repeats the motif 
	on the same pitch</b></a> because <i>minpitch</i> and <i>maxpitch</i> 
	are both set to the same pitch (60).</li><br />
	<br />

	<li>With TEXTURE MOTIFSIN, a harmonic grid is also used, so the motif will 
	repeat on a pitch selected (at random) from this grid.  A bit of compositional 
	planning is needed to get a sensible relationship between harmonic grid and 
	the motif(s) that will use it.  The possibilities for play are endless.</li>	<br />
	<br />

	<li>The second example uses MOTIFSIN, adding a simple harmonic grid to the 
	note data file:
	<pre>
	60
	#2
	0 1 60 0 0
	0 1 64 0 0
	</pre>
	Thus the program will choose (randomly) to start each note event on one or 
	the other of these pitches.  The pitch fields are adjusted accordingly:  60 
	and 64 because the span in the parameters must match the span in the note data 
	file &#150; if less, pitches in the harmonic grid will be omitted.  Also, we 
	here use different values for the MULT paramters, to give a randomly different 
	tempo for each note event:  <i>multlo</i> = 1 and <i>multhi</i> = 1.5.  The 
	result <a href="txsnd1motif2.mp3"><b>phases the motif</b></a>, which is suggestive 
	of many musical possibilities.</li><br />
	<br />

	<li>Notice that with <b>motifs</b>, the timing is part of the 
	definition of the motif itself.  The <i>amplitude</i> and <i>duration 
	fields</i> are also set.</li><br />
	<br />

	<li>A <b>timing grid</b> can also be used together with fully defined motifs, 
	thus defining exactly when the motifs will come in:  TEXTURE TMOTIFS  and, 
	with a harmonic field or set, TEXTURE TMOTIFSIN.</li>
	</ul>
</p>

<h3 id="TXNS">LINES: &nbsp;NODAL SUBSTRUCTURE &amp; MOTIFS</h3>

<p>
Beside the above possibilities, there can also be fully defined motifs 
that are placed on <b>linear shapes</b>.  These comprise <b>timed pitch 
nodes</b>.  I like to call these timed pitch nodes 'nodal substructures' 
in order to emphasise that other shapes are placed on them.  They are like  
the contour shape 'backbone' of melodic forms, and the timing dimension 
gives considerable control over how the motifs are spread out or overlap.  
This is illustrated in the examples below, because they pull together a 
number of features.
</p>

<p>
The DECORATED and ORNATE Sets allow you set a nodal substructure, the 
first on its own and the second with the addition of fully defined motifs as 
well &#150; in this case called 'ornaments'.  The note data file below shows a 
nodal substructure followed by a motif (ornament) and is for use with POSTORNATE.  
The 'POST' in the name means that the ornaments follow after (i.e., start 
on) the times specified in the nodal substructure.

<p>
The <b>first example</b> uses TEXTURE POSTORNATE and <a href="txsnd1nstune1.mp3">
<b>repeats the motif</b></a>, starting each on a different pitch, i.e., on 
a different node of the substructure.  There is no overlap because <i>skiptime</i> 
(5 sec.) is longer than the motif.  This is its note data file, <i>ndfnstune1.txt</i>:
<pre>
60                 <font color="#FF0000">reference pitch</font>
#5                 <font color="#FF0000">nodal substructure</font>
 0 1 60 0 0
 5 1 65 0 0
10 1 67 0 0
15 1 63 0 0
20 1 65 0 0
#6                 <font color="#FF0000">motif ('ornament')</font>
0.0  1 60 64 1.0
0.5  1 65 74 1.0
1.0  1 67 84 2.0
2.5  1 63 74 1.0
2.75 1 62 68 0.7
3.0  1 65 78 2.5
</pre>
The <i>outdur</i> is set to 25 seconds, to give plenty of time for all this to 
work itself out.  The output soundfile is about 35 seconds long.  Note that there 
is no pitch parameter in POSTORNATE, as all the pitches are specified in the 
note data file.
</p>

<p>
The <b>second example</b> creates <a href="txsnd1nstune2.mp3"><b>overlap in two 
ways</b></a>:  the time between nodes is less than the length of the motif.  This 
time, 2.5 seconds, is also set in <i>skiptime</i> so that the repeat of the nodal 
substructure stays in sync.  Also, the pitch at 2.5 duplicates the one at 0.0 
(60), and the one at 7.5 duplicates the one at 5.0 (67).  The overlap creates 
harmonies inherent in the motif itself when the second one starts later but on 
the same pitch.  <i>Ndfnstune2.txt</i> is as follows:
<pre>
60               <font color="#FF0000">Original tuned to Middle-C</font>
#5               <font color="#FF0000">5 lines in 'line' (nodal substructure)</font>
 0.0 1 60 0 0    <font color="#FF0000">1st node is Middle-C</font>
 2.5 1 60 0 0    <font color="#FF0000">motif repeats on Middle-C, with overlap)</font>
 5.0 1 67 0 0    <font color="#FF0000">node moves to G</font>
 7.5 1 67 0 0    <font color="#FF0000">motif repeats on G</font>
10.0 1 65 0 0    <font color="#FF0000">motif moves down to Eb</font>
#5               <font color="#FF0000">5 lines in the motif; amp & dur fields used</font>
0.0 1 60 64 1.0  <font color="#FF0000">motif starts on Middle-C</font>
0.5 1 65 74 1.0  <font color="#FF0000">and moves up to F</font>
1.0 1 67 84 2.0  <font color="#FF0000">dur longer to last till next note</font>
2.5 1 63 74 1.0  <font color="#FF0000">motif continues on Eb</font>
2.75 1 63 74 1.0 <font color="#FF0000">an 'escape tone' embellishment is added</font>
3.0 1 65 78 2.5  <font color="#FF0000">final pitch is F</font>
</pre>
</p>

<p>
The <b>final example</b> illustrates an <a href="txsnd1nstune3.mp3"><b>advancing 
overlap</b></a>: the time between repeats gets smaller.
</p>

<p>
I have tried to make it easy to hear what is happening with these examples, but the 
principle involved in handling the nodal substructure is very powerful, given care 
over designing motifs to achieve specific musical results.  More than one motif can 
be used (the program will select randomly among them when initiating the motifs) and 
the MULT fields can be used for varying tempi, so there is much to explore.  
The note data file for this example is:
<pre>
60                <font color="#FF0000">reference pitch</font>
#5                <font color="#FF0000">nodal substructure</font>
 0.0 1 60 0 0
 4.0 1 64 0 0
 6.0 1 67 0 0
 7.0 1 60 0 0
 7.5 1 64 0 0
#6                <font color="#FF0000">motif ('ornament')</font>
0.0  1 60 64 1.0
0.5  1 65 74 1.0
1.0  1 67 84 2.0
2.5  1 63 74 1.0
2.75 1 62 68 0.7
3.0  1 65 78 2.5
</pre>
</p>

<p>
In the DECORATED group of programs (PRE- and POST- as well), the nodal substructure is 
defined, but the motif itself is not.  It is created on the fly according to your 
parameter settings, making for a more flexible result.
</p>

<h3 id="TXPLAY">CONCLUSION: PLAY BETWEEN RANDOMISED &amp; DEFINED</h3>

<p>
<b>The third key to the TEXTURE Set of programs</b> is to understand how they 
can be used to play with both randomised and fully defined 
musical features. Note that 'randomised' selections can be constrained to a 
harmonic field in various ways in Modes <b>1-4</b>.  We have seen all of these 
features above, but this <b>summarises the play between randomised and 
defined</b>.
	<ul>
	<li><b>decorations on a nodal substructure</b> &#150; these 
	note groupings with randomised features that get attached 
	to a defined set of pitches (the 'nodal substructure')</li><br />
	<br />
	<li><b>rhythms</b> &#150; these define a rhythmic grid onto 
	which randomly selected notes are 'snapped'.</li><br />
	<br />
	<li><b>ornaments on a nodal substructure</b> &#150; here, fully 
	defined note groupings (pitch and rhythm defined) are 
	placed on a defined set of pitches (the 'nodal substructure'), 
	but the timings of the nodes enable you to control overlaps 
	with great precision, create canons etc.</li><br />
	<br />

	<li><b><i>Packing</i></b> sets the density of the note events (their 
	temporal location) and can change over time.  It also has 
	an offset that randomises these occurences &#150; a 'humanise' 
	function (the <i>scatter</i> parameter).</li><br />
	<br />

	<li>As with many CDP parameters, most TEXTURE parameters can be 
	<b>constants</b>, <b>random selections between maximum and minimum values</b> 
	or <b>random selections between time-varying contour limits</b>.</li><br />
	<br />

	<li>Note that to repeat a note or ornament etc. on the <b>same 
	pitch</b>, make the maximum and minimum pitch values the same.  
	This, for example, makes it possible to create 'canons' that 
	start on the same pitch.</li><br />
	<br />

	<li>One last example for TEXTURE illustrates the <a href="txws20.mp3">
	<b>play between nodal substructure and motifs</b></a>.  It comes from the 
	<b>Texture Workshop CD-ROM</b> (No. 20).</li>
	</ul>
</p>

<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<p>
<br />
</p>

<hr><!-- ********************************************************** -->
<h2 id="STEP12">Step 12: Suggestions Regarding Project Management</h2>

<blockquote>
<p>
There are so many possibilities for the precise sculpting of sound in the 
CDP Software, that it can be an efficient use of time to take some trouble 
over documenting your work as you go, especially sounds that really please you.  
The history or log files help with this.  Here are a few suggestions for your 
consideration.
	<ul>
	<li>Maintain a separate overall folder for a project, possibly 
	with subfolders for source sounds &amp; modifications to the 
	source material, building chordal material, assembly with 
	texture and mixing, or some other processing category used 
	extensively in that project.</li><br />
	<br />

	<li>Keep a hard-cover notebook for jotting ideas, roughing out 
	the breakpoint files, mixes, harmonies, and parameters of 
	effective transformations.  This gives you a permanent record 
	of your work, sources used, effective transformations achieved 
	and precisely how they were done, names of files etc.  So much 
	is achieved in one day on the computer, that it is hard to 
	remember very much even from the previous day's session!  Coloured 
	flags can be used to index important pages.</li><br />
	<br />

	<li>Code the names of soundfiles and related breakpoint and text files 
	with the same initial letters.  E.g., txwater.wav, with txwaterndf.txt and 
	txwaterpk.brk.  Then you can easily see which files went into the making 
	of a particular sound, and find them again when you want to edit them.</li><br />
	<br />
	
	<li>Remember to SAVE a session's work with <i>Soundshaper's</i> 
	<b>History</b> function (<a href="../../html/filestxt.htm#SSHISTORYFILES">
	<b>.hst</b> files</a>).  <i>Sound Loom</i> history is saved 
	automatically.</li>
	</ul>
</p>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>

<hr><!-- ********************************************************** -->
<h2  id="CONCLUSION">CONCLUSION</h2>

<blockquote>
<p>
The above survey by no means exhausts the functionality of the CDP 
software.  For example, we haven't even touched on granular manipulations 
or a host of the spectral functions.  The aim has been to lay out the 
basic components of the system and how to use them, opening the way 
to more thorough creative explorations by yourselves.  It is absolutely 
fascinating how different the objectives and results can be.  My parting 
advice is to accept your individuality, the uniqueness of your life 
history and perceptions, trust yourself and, in the words of the 
sculptor Paolozzi, 'Follow your preferences'.
</p>
<p>
<a href="#INDEX"><b>Return</b></a> to 12-Step Index
</p>
</blockquote>


<!-- ========================================================================= -->



<!-- ********************************************************** -->
  <div id = "footer">
   <p>
    <address>
    Last Updated 30 Oct 2021 -- HTML5 version<br />
    Documentation: Archer Endrich<br />
    Revisions: Robert Fraser<br>
    All observations &amp; ideas for improvement appreciated<br />
    Composers Desktop Project Ltd<br />
    Email: cdpse9@gmail.com<br />
    &#169; Copyright 1998-2021 Archer Endrich &amp; CDP<br>
    </address>
   </p>
  </div>

</div> <!-- End of 'right' (contents) indentation -->

</body>

</html>